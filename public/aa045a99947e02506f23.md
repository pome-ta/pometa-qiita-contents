---
title: Pythonista3 ã§AVAudioSourceNode ã‚’ä½¿ã£ã¦éŸ³ã‚’ç”Ÿæˆã—ã¦é³´ã‚‰ãã†ï¼ å¾Œç·¨
tags:
  - Python
  - Mobile
  - MobileApp
  - AVAudioEngine
  - Pythonista3
private: false
updated_at: '2022-12-16T07:01:08+09:00'
id: aa045a99947e02506f23
organization_url_name: null
slide: false
ignorePublish: false
---

ã“ã®è¨˜äº‹ã¯ã€[Pythonista3 Advent Calendar 2022](https://qiita.com/advent-calendar/2022/pythonista3) ã® 16 æ—¥ç›®ã®è¨˜äº‹ã§ã™ã€‚

ğŸ‘‡ : 15 æ—¥ç›®

https://qiita.com/pome-ta/items/92a41e15b8eec5b51fb3

ğŸ‘‡ : 17 æ—¥ç›®

https://qiita.com/pome-ta/items/551bf5fb2448ddcacae0

https://qiita.com/advent-calendar/2022/pythonista3

ä¸€æ–¹çš„ãªåã£ãŸç›®ç·šã§ã€Pythonista3 ã‚’ç´¹ä»‹ã—ã¦ã„ãã¾ã™ã€‚

ã»ã¼æ¯æ—¥ iPhoneï¼ˆPythonista3ï¼‰ã§ã€ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã‚’ã—ã¦ã„ã‚‹è€…ã§ã™ã€‚ã‚ˆã‚ã—ããŠé¡˜ã„ã—ã¾ã™ã€‚

ä»¥ä¸‹ã€ç§ã® 2022 å¹´ 12 æœˆæ™‚ç‚¹ã®ç’°å¢ƒã§ã™ã€‚

```sysInfo.log
--- SYSTEM INFORMATION ---
* Pythonista 3.3 (330025), Default interpreter 3.6.1
* iOS 16.1.1, model iPhone12,1, resolution (portrait) 828.0 x 1792.0 @ 2.0
```

ä»–ã®ç’°å¢ƒ(iPad ã‚„ç«¯æœ«ã®ç¨®é¡ã€iOS ã®ãƒãƒ¼ã‚¸ãƒ§ãƒ³é•ã„)ã§ã¯ã€æ„å›³ã¨ã—ãªã„æŒ™å‹•(ã‚¨ãƒ©ãƒ¼ã«ãªã‚‹)ãªã‚‹å ´åˆã‚‚ã‚ã‚Šã¾ã™ã€‚ã”äº†æ‰¿ãã ã•ã„ã€‚

ã¡ãªã¿ã«ã€`model iPhone12,1` ã¯ã€iPhone11 ã§ã™ã€‚

## å‰å›ã¾ã§ã®ã‚ã‚‰ã™ã˜

- éŸ³ã‚’å‡ºã›ãŸ
  - `objc_util` ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã§`AVAudioEngine` ã‚’ä¸­å¿ƒã«å®Ÿè£…
    - `AVAudioSourceNode`
      - `ObjCBlock` ã§ã€éŸ³å£°ãƒ‡ãƒ¼ã‚¿ã®ãƒ«ãƒ¼ãƒ†ã‚£ãƒ³ã‚°
        - æ•°å¼ã‚’ä½¿ã£ãŸ sine æ³¢ã®ç”Ÿæˆ
      - `AudioBuffer`, `AudioBufferList` æ§‹é€ ä½“ã®ä½œæˆ
    - connect ã«ã‚ˆã‚‹ Node ã®é€£çµ
- éŸ³ã‚’æ­¢ã‚ã‚‰ã‚ŒãŸ
  - `ui` ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã§ã‚¢ãƒ—ãƒªãƒ©ã‚¤ã‚¯ & çµ‚äº†æŒ‡ç¤ºã®é€£æº

ã¾ã¨ã‚ã‚‹ã¨ã€ã“ã‚“ãªã«ã•ã£ã±ã‚Šã™ã‚‹ã®ã§ã™ã­ï¼

ä»Šå›ã¯ã€æ³¢å½¢ã®ç¨®é¡ã‚’å¤‰ãˆãŸã‚Šã€å¯è¦–åŒ–ã—ãŸã‚Šã€ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ãƒ†ã‚£ãƒ–ã«æ“ä½œã§ãã‚‹ã‚ˆã†ã«ã—ã¦ã„ãã¾ã—ã‚‡ã†ï¼ï¼

`objc_util` è‰²ã¯å¼±ã‚ã§ Python ï¼ˆPythonista3ï¼‰ã®å‡¦ç†ãŒä¸­å¿ƒã§ã™ã€‚

```å‰å›ã¾ã§ã®ã‚³ãƒ¼ãƒ‰.py
from math import sin, pi
import ctypes

from objc_util import ObjCClass, ObjCBlock
import ui

import pdbg

CHANNEL = 1

OSStatus = ctypes.c_int32

AVAudioEngine = ObjCClass('AVAudioEngine')
AVAudioSourceNode = ObjCClass('AVAudioSourceNode')
AVAudioFormat = ObjCClass('AVAudioFormat')


class AudioBuffer(ctypes.Structure):
  _fields_ = [
    ('mNumberChannels', ctypes.c_uint32),
    ('mDataByteSize', ctypes.c_uint32),
    ('mData', ctypes.c_void_p),
  ]


class AudioBufferList(ctypes.Structure):
  _fields_ = [
    ('mNumberBuffers', ctypes.c_uint32),
    ('mBuffers', AudioBuffer * CHANNEL),
  ]


class Synth:
  def __init__(self):
    self.audioEngine: AVAudioEngine
    self.sampleRate: float = 44100.0  # set_up ãƒ¡ã‚½ãƒƒãƒ‰: outputNode ã‚ˆã‚Šç¢ºå®š
    self.deltaTime: float = 0.0  # 1/sampleRate æ™‚é–“é–“éš”
    self.timex: float = 0.0  # Render ã®é–“éš”ã‚«ã‚¦ãƒ³ã‚¿ãƒ¼

    self.render_block = ObjCBlock(
      self.source_node_render,
      restype=OSStatus,
      argtypes=[
        ctypes.c_void_p, ctypes.c_void_p, ctypes.c_void_p, ctypes.c_void_p,
        ctypes.POINTER(AudioBufferList)
      ])

    self.set_up()

  def set_up(self):
    audioEngine = AVAudioEngine.new()
    sourceNode = AVAudioSourceNode.alloc()
    mainMixer = audioEngine.mainMixerNode()
    outputNode = audioEngine.outputNode()
    format = outputNode.inputFormatForBus_(0)

    self.sampleRate = format.sampleRate()
    self.deltaTime = 1 / self.sampleRate

    inputFormat = AVAudioFormat.alloc(
    ).initWithCommonFormat_sampleRate_channels_interleaved_(
      format.commonFormat(), self.sampleRate, CHANNEL, format.isInterleaved())

    sourceNode.initWithFormat_renderBlock_(inputFormat, self.render_block)

    audioEngine.attachNode_(sourceNode)
    sourceNode.volume = 0.5

    audioEngine.connect_to_format_(sourceNode, mainMixer, inputFormat)
    audioEngine.connect_to_format_(mainMixer, outputNode, inputFormat)

    audioEngine.prepare()
    self.audioEngine = audioEngine

  def source_node_render(self,
                         _cmd: ctypes.c_void_p,
                         _isSilence_ptr: ctypes.c_void_p,
                         _timestamp_ptr: ctypes.c_void_p,
                         frameCount: ctypes.c_void_p,
                         outputData_ptr: ctypes.POINTER) -> OSStatus:
    ablPointer = outputData_ptr.contents
    for frame in range(frameCount):
      # å‡ºåŠ›æ³¢å½¢ã‚’å¤‰ãˆã¦ã„ã
      sampleVal = sin(440.0 * 2.0 * pi * self.timex)
      self.timex += self.deltaTime

      for bufferr in range(ablPointer.mNumberBuffers):
        _mData = ablPointer.mBuffers[bufferr].mData
        _pointer = ctypes.POINTER(ctypes.c_float * frameCount)
        buffer = ctypes.cast(_mData, _pointer).contents
        buffer[frame] = sampleVal
    return 0

  def start(self):
    self.audioEngine.startAndReturnError_(None)

  def stop(self):
    self.audioEngine.stop()


class View(ui.View):
  def __init__(self, *args, **kwargs):
    ui.View.__init__(self, *args, **kwargs)
    self.synth = Synth()
    self.synth.start()

  def will_close(self):
    self.synth.stop()


if __name__ == '__main__':
  view = View()
  view.present()
  #view.present(style='fullscreen', orientations=['portrait'])

```

## ã‚ªã‚·ãƒ¬ãƒ¼ã‚¿ãƒ¼ã‚’ã¤ãã‚‹

Oscillatorï¼ˆç™ºæŒ¯å™¨ãƒ»OSCï¼‰ã¯ã€ã‚·ãƒ³ã‚»ã‚µã‚¤ã‚¶ãƒ¼ã§åŸºæœ¬æ³¢å½¢ã‚’ä½œã‚Šå‡ºã™æ©Ÿèƒ½ã§ã™ã€‚

- æ­£å¼¦æ³¢: sine
- ä¸‰è§’æ³¢: triangle
- ãƒã‚³ã‚®ãƒªæ³¢: sawtooth
- çŸ©å½¢æ³¢: square

[Building a Synthesizer in Swift. Making audio waveforms withâ€¦ | by SwiftMoji | Better Programming](https://betterprogramming.pub/building-a-synthesizer-in-swift-866cd15b731)

https://betterprogramming.pub/building-a-synthesizer-in-swift-866cd15b731

ã“ã¡ã‚‰ã‚’å‚è€ƒã«ä½œã£ã¦ã„ãã¾ã™ã€‚

### White Noise

ãŠãƒ¼ã£ã¨ã€æ—©é€Ÿ OSC ã§ç´¹ä»‹ã—ã¦ã„ãªã„ã®ãŒã§ã¦ãã¾ã—ãŸã­ ğŸ˜‡

é¢ç™½ã„ã§ã™ã—ã€å…ˆã€…ã«ã‚„ã£ã¦ã—ã¾ã£ãŸæ–¹ãŒã„ã„ã¨æ€ã„ã¾ã—ã¦ã€å…ˆã«å®Ÿè£…ã—ã¾ã™ã€‚

```whiteNoise.py
from random import uniform

# --- sine
#sampleVal = sin(440.0 * 2.0 * pi * self.timex)
# --- whiteNoise
sampleVal = uniform(-1.0, 1.0)
```

`random.random()` ã§ã™ã¨ã€0.0 ä»¥ä¸Š 1.0 æœªæº€ ã®æŠ½å‡ºã§ã™ã€‚

éŸ³å£°ãƒ‡ãƒ¼ã‚¿ã¨ã—ã¦`-1.0 ã€œ 1.0` ãŒæ¬²ã—ã„ã®ã§ã€`random.uniform(-1.0, 1.0)` ã§ç¯„å›²ã‚’æŒ‡å®šã—ã¦ã„ã¾ã™ã€‚

ç ‚åµã®éŸ³ã«ãªã‚Šã¾ã—ãŸã­ï¼ˆç¾ä»£äººã¯ã€ãƒ†ãƒ¬ãƒ“ã‚„ãƒ©ã‚¸ã‚ªã®ãƒã‚¤ã‚ºéŸ³ã¨ã‹çŸ¥ã‚‰ãªã„ã‚“ã ã‚ã†ãªï¼‰ã€‚

White Noise ä»¥é™ã¯ã€é–¢æ•°åŒ–ã—ã¦ä½œæˆã—ã¦ã„ãã¾ã™ã€‚

### æ­£å¼¦æ³¢: sine

ã™ã§ã«ã€å‰å›ã§å‘¼ã³å‡ºã—ç¢ºèªãŒã§ãã¦ã‚‹`sine` ã§ã™ãŒã€é–¢æ•°åŒ–ã‚’ã—ã¦ã„ãã¾ã™ã€‚

`amplitude`ï¼ˆæŒ¯å¹…ï¼‰ã¨`frequency`ï¼ˆå‘¨æ³¢æ•°ï¼‰ã‚’å¤‰æ•°ã¨ã—ã¦äº‹å‰ã«å®šç¾©ã—ã¦ãŠãã¾ã™ã€‚

ï¼ˆæŒ¯å¹…ã‚„å‘¨æ³¢æ•°ç­‰ã®èª¬æ˜ã«é–¢ã—ã¦ã¯ã“ã“ã§ã¯å‰²æ„›ã•ã›ã¦ã„ãŸã ãã¾ã™ï¼‰

```py
# --- OSC
amplitude: float = 1.0
frequency: float = 440.0


def sine(time):
  wave = amplitude * sin(2.0 * pi * frequency * time)
  return wave

```

å…¨ä½“åƒ:

```sineã‚’è¿½åŠ .py
from math import sin, pi
from random import uniform
import ctypes

from objc_util import ObjCClass, ObjCBlock
import ui

import pdbg

CHANNEL = 1

OSStatus = ctypes.c_int32

AVAudioEngine = ObjCClass('AVAudioEngine')
AVAudioSourceNode = ObjCClass('AVAudioSourceNode')
AVAudioFormat = ObjCClass('AVAudioFormat')


class AudioBuffer(ctypes.Structure):
  _fields_ = [
    ('mNumberChannels', ctypes.c_uint32),
    ('mDataByteSize', ctypes.c_uint32),
    ('mData', ctypes.c_void_p),
  ]


class AudioBufferList(ctypes.Structure):
  _fields_ = [
    ('mNumberBuffers', ctypes.c_uint32),
    ('mBuffers', AudioBuffer * CHANNEL),
  ]


# --- OSC
amplitude: float = 1.0
frequency: float = 440.0


def white_noise():
  return uniform(-1.0, 1.0)


def sine(time):
  wave = amplitude * sin(2.0 * pi * frequency * time)
  return wave


class Synth:
  def __init__(self):
    self.audioEngine: AVAudioEngine
    self.sampleRate: float = 44100.0  # set_up ãƒ¡ã‚½ãƒƒãƒ‰: outputNode ã‚ˆã‚Šç¢ºå®š
    self.deltaTime: float = 0.0  # 1/sampleRate æ™‚é–“é–“éš”
    self.timex: float = 0.0  # Render ã®é–“éš”ã‚«ã‚¦ãƒ³ã‚¿ãƒ¼

    self.render_block = ObjCBlock(
      self.source_node_render,
      restype=OSStatus,
      argtypes=[
        ctypes.c_void_p, ctypes.c_void_p, ctypes.c_void_p, ctypes.c_void_p,
        ctypes.POINTER(AudioBufferList)
      ])

    self.set_up()

  def set_up(self):
    audioEngine = AVAudioEngine.new()
    sourceNode = AVAudioSourceNode.alloc()
    mainMixer = audioEngine.mainMixerNode()
    outputNode = audioEngine.outputNode()
    format = outputNode.inputFormatForBus_(0)

    self.sampleRate = format.sampleRate()
    self.deltaTime = 1 / self.sampleRate

    inputFormat = AVAudioFormat.alloc(
    ).initWithCommonFormat_sampleRate_channels_interleaved_(
      format.commonFormat(), self.sampleRate, CHANNEL, format.isInterleaved())

    sourceNode.initWithFormat_renderBlock_(inputFormat, self.render_block)

    audioEngine.attachNode_(sourceNode)
    sourceNode.volume = 0.2

    audioEngine.connect_to_format_(sourceNode, mainMixer, inputFormat)
    audioEngine.connect_to_format_(mainMixer, outputNode, inputFormat)

    audioEngine.prepare()
    self.audioEngine = audioEngine

  def source_node_render(self,
                         _cmd: ctypes.c_void_p,
                         _isSilence_ptr: ctypes.c_void_p,
                         _timestamp_ptr: ctypes.c_void_p,
                         frameCount: ctypes.c_void_p,
                         outputData_ptr: ctypes.POINTER) -> OSStatus:
    ablPointer = outputData_ptr.contents
    for frame in range(frameCount):
      # å‡ºåŠ›æ³¢å½¢ã‚’å¤‰ãˆã¦ã„ã
      # --- sine
      #sampleVal = sin(440.0 * 2.0 * pi * self.timex)
      # --- whiteNoise
      #sampleVal = uniform(-1.0, 1.0)
      #sampleVal = white_noise()
      # --- sine
      sampleVal = sine(self.timex)

      self.timex += self.deltaTime

      for bufferr in range(ablPointer.mNumberBuffers):
        _mData = ablPointer.mBuffers[bufferr].mData
        _pointer = ctypes.POINTER(ctypes.c_float * frameCount)
        buffer = ctypes.cast(_mData, _pointer).contents
        buffer[frame] = sampleVal
    return 0

  def start(self):
    self.audioEngine.startAndReturnError_(None)

  def stop(self):
    self.audioEngine.stop()


class View(ui.View):
  def __init__(self, *args, **kwargs):
    ui.View.__init__(self, *args, **kwargs)
    self.synth = Synth()
    self.synth.start()

  def will_close(self):
    self.synth.stop()


if __name__ == '__main__':
  view = View()
  view.present()
  #view.present(style='fullscreen', orientations=['portrait'])

```

ä»–ã®æ³¢ã®é–¢æ•°ã¯ã€`sine` ã®ä¸‹ã«è¿½åŠ ã—ã¦ã„ãã¾ã™ã€‚

ã•ã£ãã‚Šé–¢æ•°ã®ã¿ç´¹ä»‹ã—ã¦ã„ãã¾ã™ï¼ˆã“ã®å¾Œ class åŒ–ã‚‚ã—ã¦ã„ãã®ã§é¢å€’ãªã‚‰è¦‹ã¦ã‚‹ã ã‘ã§ã‚‚ã„ã„ã‹ã‚‚ã—ã‚Œã¾ã›ã‚“ï¼‰ã€‚

### ä¸‰è§’æ³¢: triangle

```py
def triangle(time):
  period = 1.0 / frequency
  currentTime = time % period
  value = currentTime / period
  result = 0.0
  if value < 0.25:
    result = value * 4
  elif value < 0.75:
    result = 2.0 - (value * 4.0)
  else:
    result = value * 4 - 4.0
  wave = amplitude * result
  return wave
```

### ãƒã‚³ã‚®ãƒªæ³¢: sawtooth

```py
def sawtooth(time):
  period = 1.0 / frequency
  currentTime = time % period
  wave = amplitude * ((currentTime / period) * 2 - 1.0)
  return wave
```

### çŸ©å½¢æ³¢: square

```py
def square(time):
  period = 1.0 / frequency
  currentTime = time % period
  if (currentTime / period) < 0.5:
    wave = amplitude
  else:
    wave = -1.0 * amplitude
  return wave
```

### class åŒ–ã¨ã€ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ãƒ†ã‚£ãƒ–ãªæ‹¡å¼µæ€§

```é–¢æ•°å®Ÿè£….py
from math import sin, pi
from random import uniform
import ctypes

from objc_util import ObjCClass, ObjCBlock
import ui

import pdbg

CHANNEL = 1

OSStatus = ctypes.c_int32

AVAudioEngine = ObjCClass('AVAudioEngine')
AVAudioSourceNode = ObjCClass('AVAudioSourceNode')
AVAudioFormat = ObjCClass('AVAudioFormat')


class AudioBuffer(ctypes.Structure):
  _fields_ = [
    ('mNumberChannels', ctypes.c_uint32),
    ('mDataByteSize', ctypes.c_uint32),
    ('mData', ctypes.c_void_p),
  ]


class AudioBufferList(ctypes.Structure):
  _fields_ = [
    ('mNumberBuffers', ctypes.c_uint32),
    ('mBuffers', AudioBuffer * CHANNEL),
  ]


# --- OSC
amplitude: float = 1.0
frequency: float = 440.0


def white_noise():
  return uniform(-1.0, 1.0)


def sine(time):
  wave = amplitude * sin(2.0 * pi * frequency * time)
  return wave


def triangle(time):
  period = 1.0 / frequency
  currentTime = time % period
  value = currentTime / period
  result = 0.0
  if value < 0.25:
    result = value * 4
  elif value < 0.75:
    result = 2.0 - (value * 4.0)
  else:
    result = value * 4 - 4.0
  wave = amplitude * result
  return wave


def sawtooth(time):
  period = 1.0 / frequency
  currentTime = time % period
  wave = amplitude * ((currentTime / period) * 2 - 1.0)
  return wave


def square(time):
  period = 1.0 / frequency
  currentTime = time % period
  if (currentTime / period) < 0.5:
    wave = amplitude
  else:
    wave = -1.0 * amplitude
  return wave


class Synth:
  def __init__(self):
    self.audioEngine: AVAudioEngine
    self.sampleRate: float = 44100.0  # set_up ãƒ¡ã‚½ãƒƒãƒ‰: outputNode ã‚ˆã‚Šç¢ºå®š
    self.deltaTime: float = 0.0  # 1/sampleRate æ™‚é–“é–“éš”
    self.timex: float = 0.0  # Render ã®é–“éš”ã‚«ã‚¦ãƒ³ã‚¿ãƒ¼

    self.render_block = ObjCBlock(
      self.source_node_render,
      restype=OSStatus,
      argtypes=[
        ctypes.c_void_p, ctypes.c_void_p, ctypes.c_void_p, ctypes.c_void_p,
        ctypes.POINTER(AudioBufferList)
      ])

    self.set_up()

  def set_up(self):
    audioEngine = AVAudioEngine.new()
    sourceNode = AVAudioSourceNode.alloc()
    mainMixer = audioEngine.mainMixerNode()
    outputNode = audioEngine.outputNode()
    format = outputNode.inputFormatForBus_(0)

    self.sampleRate = format.sampleRate()
    self.deltaTime = 1 / self.sampleRate

    inputFormat = AVAudioFormat.alloc(
    ).initWithCommonFormat_sampleRate_channels_interleaved_(
      format.commonFormat(), self.sampleRate, CHANNEL, format.isInterleaved())

    sourceNode.initWithFormat_renderBlock_(inputFormat, self.render_block)

    audioEngine.attachNode_(sourceNode)
    sourceNode.volume = 0.2

    audioEngine.connect_to_format_(sourceNode, mainMixer, inputFormat)
    audioEngine.connect_to_format_(mainMixer, outputNode, inputFormat)

    audioEngine.prepare()
    self.audioEngine = audioEngine

  def source_node_render(self,
                         _cmd: ctypes.c_void_p,
                         _isSilence_ptr: ctypes.c_void_p,
                         _timestamp_ptr: ctypes.c_void_p,
                         frameCount: ctypes.c_void_p,
                         outputData_ptr: ctypes.POINTER) -> OSStatus:
    ablPointer = outputData_ptr.contents
    for frame in range(frameCount):
      # å‡ºåŠ›æ³¢å½¢ã‚’å¤‰ãˆã¦ã„ã
      # --- whiteNoise
      #sampleVal = uniform(-1.0, 1.0)
      #sampleVal = white_noise()
      # --- sine
      #sampleVal = sin(440.0 * 2.0 * pi * self.timex)
      #sampleVal = sine(self.timex)
      # --- triangle
      #sampleVal = triangle(self.timex)
      # --- sawtooth
      #sampleVal = sawtooth(self.timex)
      # --- square
      sampleVal = square(self.timex)

      self.timex += self.deltaTime

      for bufferr in range(ablPointer.mNumberBuffers):
        _mData = ablPointer.mBuffers[bufferr].mData
        _pointer = ctypes.POINTER(ctypes.c_float * frameCount)
        buffer = ctypes.cast(_mData, _pointer).contents
        buffer[frame] = sampleVal
    return 0

  def start(self):
    self.audioEngine.startAndReturnError_(None)

  def stop(self):
    self.audioEngine.stop()


class View(ui.View):
  def __init__(self, *args, **kwargs):
    ui.View.__init__(self, *args, **kwargs)
    self.synth = Synth()
    self.synth.start()

  def will_close(self):
    self.synth.stop()


if __name__ == '__main__':
  view = View()
  view.present()
  #view.present(style='fullscreen', orientations=['portrait'])

```

ä¸€é€šã‚Šå®Ÿè£…ãŒå®Œäº†ã—ã¾ã—ãŸã€‚ãŒã€`Oscillator` ã¨ã—ã¦ class åŒ–ã—ãŸæ–¹ãŒéƒ½åˆãŒè‰¯ã•ãã†ã§ã™ã­ã€‚

ã„ã¾ã¯`Synth` ã® Render ãƒ¡ã‚½ãƒƒãƒ‰å†…ã§ã€æ¯å›æ›¸ãæ›ãˆï¼ˆã‚³ãƒ¡ãƒ³ãƒˆã‚¢ã‚¦ãƒˆï¼‰ã¦ã€ãã‚Œãã‚Œã®æ³¢ã‚’é¸ã‚“ã§ã„ã‚‹ã®ã§ã€ç¢ºèªã®ã‚¤ãƒ†ãƒ¬ãƒ¼ãƒˆã‚‚é¢å€’ã§ã™ã€‚

#### `class Oscillator:`

ã²ã¨ã¾ã¨ã‚ã«ã—ã¾ã—ãŸã€‚

`self.wave_types` ã®é…åˆ—ã§æ³¢ã®é–¢æ•°ã‚’ index ã§å‘¼ã³å‡ºã›ã‚‹ã‚ˆã†ã«ã—ã¦ã„ã¾ã™ã€‚

ã¾ãŸã€`white_noise` ãƒ¡ã‚½ãƒƒãƒ‰ã¯ã€å¼•æ•°ãŒä¸è¦ã§ã™ãŒãƒ¡ã‚½ãƒƒãƒ‰å…¨ä½“ã¨æ•´ãˆã‚‹å¿…è¦ãŒã‚ã‚‹ãŸã‚ã€`_` ã¨ã—ã¦ã„ã¾ã™ã€‚

```classã®éƒ¨åˆ†ã®ã¿.py
class Oscillator:
  def __init__(self):
    self.amplitude: float = 1.0
    self.frequency: float = 440.0
    self.wave_types = [
      self.sine,
      self.triangle,
      self.sawtooth,
      self.square,
      self.white_noise,
    ]

  def sine(self, time):
    wave = self.amplitude * sin(2.0 * pi * self.frequency * time)
    return wave

  def triangle(self, time):
    period = 1.0 / self.frequency
    currentTime = time % period
    value = currentTime / period
    result = 0.0
    if value < 0.25:
      result = value * 4
    elif value < 0.75:
      result = 2.0 - (value * 4.0)
    else:
      result = value * 4 - 4.0
    wave = self.amplitude * result
    return wave

  def sawtooth(self, time):
    period = 1.0 / self.frequency
    currentTime = time % period
    wave = self.amplitude * ((currentTime / period) * 2 - 1.0)
    return wave

  def square(self, time):
    period = 1.0 / self.frequency
    currentTime = time % period
    if (currentTime / period) < 0.5:
      wave = self.amplitude
    else:
      wave = -1.0 * self.amplitude
    return wave

  def white_noise(self, _):
    return uniform(-1.0, 1.0)
```

#### ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ãƒ†ã‚£ãƒ–ã«

å®Ÿè¡Œæ™‚ã«å¤‰åŒ–ã•ã›ã‚‹ã‚ˆã†ã«ã€class `View` ã¨ã—ã¦ã„ã‚‹`ui.View` ã®ä¸­ã«ã€ã‚¹ãƒ©ã‚¤ãƒ€ãƒ¼ã§é¸æŠã§ãã‚‹ã‚ˆã†ã«çµ„ã¿è¾¼ã‚“ã§ã„ãã¾ã™ã€‚

##### osc é¸æŠ

```py
def setup_type_slider(self):
  self.type_len = len(self.osc.wave_types) - 1
  self.type_osc = ui.Slider()
  self.type_osc.continuous = False
  self.type_osc.value = 0
  self.type_osc.flex = 'W'
  self.type_osc.action = self.change_osc
  self.add_subview(self.type_osc)

def change_osc(self, sender):
  val = int(sender.value * self.type_len)
  self.toneGenerator = self.osc.wave_types[val]
  self.type_osc.value = val / self.type_len
  print(self.toneGenerator)  # â† ä»Šå›ã®ç¢ºèªç”¨
```

`print` ã‚’ä»•è¾¼ã‚“ã§ã„ã‚‹ã®ã§ã€ocs ã®åˆ‡ã‚Šæ›¿ã‚ã‚Šã§ç¾åœ¨ã®æ³¢ã‚’å‡ºåŠ›ã—ã¦ã„ã¾ã™ã€‚

![img221205_231256.gif](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/2953777/8f2e2b20-f863-6e5c-14e7-18b025ffc5db.gif)

`ui.Slider.continuous = False` ã«ã¦ã€ï¼ˆç§»å‹•æ™‚ã§ã¯ãªãï¼‰ã‚¹ãƒ©ã‚¤ãƒ€ãƒ¼ã®ä½ç½®ãŒ fix æ™‚ã«æ•°å€¤ã‚’é€ã‚Šå‡ºã—ã¦ã„ã¾ã™ã€‚

`val = int(sender.value * self.type_len)` ã«ã¦ã€é…åˆ— index ã‚’æŒ‡å®šã€‚

`self.type_osc.value = val / self.type_len` ã«ã¦ã€`ui.Slider.value` ã®ä½ç½®èª¿æ•´ã‚’ã„ã¦ã„ã¾ã™ã€‚

```sliderå®Ÿè£….py
from math import sin, pi
from random import uniform
import ctypes

from objc_util import ObjCClass, ObjCBlock
import ui

import pdbg

CHANNEL = 1

OSStatus = ctypes.c_int32

AVAudioEngine = ObjCClass('AVAudioEngine')
AVAudioSourceNode = ObjCClass('AVAudioSourceNode')
AVAudioFormat = ObjCClass('AVAudioFormat')


class AudioBuffer(ctypes.Structure):
  _fields_ = [
    ('mNumberChannels', ctypes.c_uint32),
    ('mDataByteSize', ctypes.c_uint32),
    ('mData', ctypes.c_void_p),
  ]


class AudioBufferList(ctypes.Structure):
  _fields_ = [
    ('mNumberBuffers', ctypes.c_uint32),
    ('mBuffers', AudioBuffer * CHANNEL),
  ]


# --- OSC
class Oscillator:
  def __init__(self):
    self.amplitude: float = 1.0
    self.frequency: float = 440.0
    self.wave_types = [
      self.sine,
      self.triangle,
      self.sawtooth,
      self.square,
      self.white_noise,
    ]

  def sine(self, time):
    wave = self.amplitude * sin(2.0 * pi * self.frequency * time)
    return wave

  def triangle(self, time):
    period = 1.0 / self.frequency
    currentTime = time % period
    value = currentTime / period
    result = 0.0
    if value < 0.25:
      result = value * 4
    elif value < 0.75:
      result = 2.0 - (value * 4.0)
    else:
      result = value * 4 - 4.0
    wave = self.amplitude * result
    return wave

  def sawtooth(self, time):
    period = 1.0 / self.frequency
    currentTime = time % period
    wave = self.amplitude * ((currentTime / period) * 2 - 1.0)
    return wave

  def square(self, time):
    period = 1.0 / self.frequency
    currentTime = time % period
    if (currentTime / period) < 0.5:
      wave = self.amplitude
    else:
      wave = -1.0 * self.amplitude
    return wave

  def white_noise(self, _):
    return uniform(-1.0, 1.0)


class Synth:
  def __init__(self, parent):
    self.parent: ui.View = parent
    self.audioEngine: AVAudioEngine
    self.sampleRate: float = 44100.0  # set_up ãƒ¡ã‚½ãƒƒãƒ‰: outputNode ã‚ˆã‚Šç¢ºå®š
    self.deltaTime: float = 0.0  # 1/sampleRate æ™‚é–“é–“éš”
    self.timex: float = 0.0  # Render ã®é–“éš”ã‚«ã‚¦ãƒ³ã‚¿ãƒ¼

    self.render_block = ObjCBlock(
      self.source_node_render,
      restype=OSStatus,
      argtypes=[
        ctypes.c_void_p, ctypes.c_void_p, ctypes.c_void_p, ctypes.c_void_p,
        ctypes.POINTER(AudioBufferList)
      ])

    self.set_up()

  def set_up(self):
    audioEngine = AVAudioEngine.new()
    sourceNode = AVAudioSourceNode.alloc()
    mainMixer = audioEngine.mainMixerNode()
    outputNode = audioEngine.outputNode()
    format = outputNode.inputFormatForBus_(0)

    self.sampleRate = format.sampleRate()
    self.deltaTime = 1 / self.sampleRate

    inputFormat = AVAudioFormat.alloc(
    ).initWithCommonFormat_sampleRate_channels_interleaved_(
      format.commonFormat(), self.sampleRate, CHANNEL, format.isInterleaved())

    sourceNode.initWithFormat_renderBlock_(inputFormat, self.render_block)

    audioEngine.attachNode_(sourceNode)
    sourceNode.volume = 0.1

    audioEngine.connect_to_format_(sourceNode, mainMixer, inputFormat)
    audioEngine.connect_to_format_(mainMixer, outputNode, inputFormat)

    audioEngine.prepare()
    self.audioEngine = audioEngine

  def source_node_render(self,
                         _cmd: ctypes.c_void_p,
                         _isSilence_ptr: ctypes.c_void_p,
                         _timestamp_ptr: ctypes.c_void_p,
                         frameCount: ctypes.c_void_p,
                         outputData_ptr: ctypes.POINTER) -> OSStatus:
    ablPointer = outputData_ptr.contents
    for frame in range(frameCount):
      sampleVal = self.parent.toneGenerator(self.timex)

      self.timex += self.deltaTime

      for bufferr in range(ablPointer.mNumberBuffers):
        _mData = ablPointer.mBuffers[bufferr].mData
        _pointer = ctypes.POINTER(ctypes.c_float * frameCount)
        buffer = ctypes.cast(_mData, _pointer).contents
        buffer[frame] = sampleVal
    return 0

  def start(self):
    self.audioEngine.startAndReturnError_(None)

  def stop(self):
    self.audioEngine.stop()


class View(ui.View):
  def __init__(self, *args, **kwargs):
    ui.View.__init__(self, *args, **kwargs)

    self.osc = Oscillator()
    self.setup_type_slider()
    self.toneGenerator = self.osc.wave_types[0]

    self.synth = Synth(self)
    self.synth.start()

  def setup_type_slider(self):
    self.type_len = len(self.osc.wave_types) - 1
    self.type_osc = ui.Slider()
    self.type_osc.continuous = False
    self.type_osc.value = 0
    self.type_osc.flex = 'W'
    self.type_osc.action = self.change_osc
    self.add_subview(self.type_osc)

  def change_osc(self, sender):
    val = int(sender.value * self.type_len)
    self.toneGenerator = self.osc.wave_types[val]
    self.type_osc.value = val / self.type_len
    print(self.toneGenerator)

  def will_close(self):
    self.synth.stop()


if __name__ == '__main__':
  view = View()
  view.present()
  #view.present(style='fullscreen', orientations=['portrait'])

```

##### frequency é¸æŠ

æ³¢å½¢ã®å¤‰æ›´ã¨åŒæ§˜ã«`frequency`ï¼ˆå‘¨æ³¢æ•°ï¼‰ã‚‚ã‚¹ãƒ©ã‚¤ãƒ€ãƒ¼ã§å¤‰æ›´ã§ãã‚‹ã‚ˆã†ã«ã—ã¾ã—ã‚‡ã†ã€‚

ã»ã¼åŒæ§˜ã®å®Ÿè£…å†…å®¹ã§ã™ã€‚`ui.Slider.continuous` ã‚’ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã®`True` ã¨ã—ã¦ãŠã‚Šã€ã‚¹ãƒ©ã‚¤ãƒ€ãƒ¼ä½ç½®ãŒå‹•ãåº¦ã«æ•°å€¤ãŒå¤‰åŒ–ã—ã¾ã™ã€‚

`self.max_level_frq = 880.0` ã¨æœ€å¤§å‘¨æ³¢æ•°ã‚’`880.0` ã¨æ±ºã‚æ‰“ã¡ã«ã—ã€`ui.Slider.value` ã®`0.0 ã€œ 1.0` ã®é–“ã® value èª¿æ•´ã‚’ã—ã¦ã„ã¾ã™ã€‚

```frequencyã‚’è¿½åŠ .py
from math import sin, pi
from random import uniform
import ctypes

from objc_util import ObjCClass, ObjCBlock
import ui

import pdbg

CHANNEL = 1

OSStatus = ctypes.c_int32

AVAudioEngine = ObjCClass('AVAudioEngine')
AVAudioSourceNode = ObjCClass('AVAudioSourceNode')
AVAudioFormat = ObjCClass('AVAudioFormat')


class AudioBuffer(ctypes.Structure):
  _fields_ = [
    ('mNumberChannels', ctypes.c_uint32),
    ('mDataByteSize', ctypes.c_uint32),
    ('mData', ctypes.c_void_p),
  ]


class AudioBufferList(ctypes.Structure):
  _fields_ = [
    ('mNumberBuffers', ctypes.c_uint32),
    ('mBuffers', AudioBuffer * CHANNEL),
  ]


# --- OSC
class Oscillator:
  def __init__(self):
    self.amplitude: float = 1.0
    self.frequency: float = 440.0
    self.wave_types = [
      self.sine,
      self.triangle,
      self.sawtooth,
      self.square,
      self.white_noise,
    ]

  def sine(self, time):
    wave = self.amplitude * sin(2.0 * pi * self.frequency * time)
    return wave

  def triangle(self, time):
    period = 1.0 / self.frequency
    currentTime = time % period
    value = currentTime / period
    result = 0.0
    if value < 0.25:
      result = value * 4
    elif value < 0.75:
      result = 2.0 - (value * 4.0)
    else:
      result = value * 4 - 4.0
    wave = self.amplitude * result
    return wave

  def sawtooth(self, time):
    period = 1.0 / self.frequency
    currentTime = time % period
    wave = self.amplitude * ((currentTime / period) * 2 - 1.0)
    return wave

  def square(self, time):
    period = 1.0 / self.frequency
    currentTime = time % period
    if (currentTime / period) < 0.5:
      wave = self.amplitude
    else:
      wave = -1.0 * self.amplitude
    return wave

  def white_noise(self, _):
    return uniform(-1.0, 1.0)


class Synth:
  def __init__(self, parent):
    self.parent: ui.View = parent
    self.audioEngine: AVAudioEngine
    self.sampleRate: float = 44100.0  # set_up ãƒ¡ã‚½ãƒƒãƒ‰: outputNode ã‚ˆã‚Šç¢ºå®š
    self.deltaTime: float = 0.0  # 1/sampleRate æ™‚é–“é–“éš”
    self.timex: float = 0.0  # Render ã®é–“éš”ã‚«ã‚¦ãƒ³ã‚¿ãƒ¼

    self.render_block = ObjCBlock(
      self.source_node_render,
      restype=OSStatus,
      argtypes=[
        ctypes.c_void_p, ctypes.c_void_p, ctypes.c_void_p, ctypes.c_void_p,
        ctypes.POINTER(AudioBufferList)
      ])

    self.set_up()

  def set_up(self):
    audioEngine = AVAudioEngine.new()
    sourceNode = AVAudioSourceNode.alloc()
    mainMixer = audioEngine.mainMixerNode()
    outputNode = audioEngine.outputNode()
    format = outputNode.inputFormatForBus_(0)

    self.sampleRate = format.sampleRate()
    self.deltaTime = 1 / self.sampleRate

    inputFormat = AVAudioFormat.alloc(
    ).initWithCommonFormat_sampleRate_channels_interleaved_(
      format.commonFormat(), self.sampleRate, CHANNEL, format.isInterleaved())

    sourceNode.initWithFormat_renderBlock_(inputFormat, self.render_block)

    audioEngine.attachNode_(sourceNode)
    sourceNode.volume = 0.1

    audioEngine.connect_to_format_(sourceNode, mainMixer, inputFormat)
    audioEngine.connect_to_format_(mainMixer, outputNode, inputFormat)

    audioEngine.prepare()
    self.audioEngine = audioEngine

  def source_node_render(self,
                         _cmd: ctypes.c_void_p,
                         _isSilence_ptr: ctypes.c_void_p,
                         _timestamp_ptr: ctypes.c_void_p,
                         frameCount: ctypes.c_void_p,
                         outputData_ptr: ctypes.POINTER) -> OSStatus:
    ablPointer = outputData_ptr.contents
    for frame in range(frameCount):
      sampleVal = self.parent.toneGenerator(self.timex)

      self.timex += self.deltaTime

      for bufferr in range(ablPointer.mNumberBuffers):
        _mData = ablPointer.mBuffers[bufferr].mData
        _pointer = ctypes.POINTER(ctypes.c_float * frameCount)
        buffer = ctypes.cast(_mData, _pointer).contents
        buffer[frame] = sampleVal
    return 0

  def start(self):
    self.audioEngine.startAndReturnError_(None)

  def stop(self):
    self.audioEngine.stop()


class View(ui.View):
  def __init__(self, *args, **kwargs):
    ui.View.__init__(self, *args, **kwargs)

    self.setup_osc()

    self.synth = Synth(self)
    self.synth.start()

  def setup_osc(self):
    self.osc = Oscillator()
    self.setup_type_slider()
    self.setup_frq_slider()
    self.toneGenerator = self.osc.wave_types[0]

  def setup_type_slider(self):
    self.type_len = len(self.osc.wave_types) - 1
    self.type_osc = ui.Slider()
    self.type_osc.continuous = False
    self.type_osc.value = 0
    self.type_osc.flex = 'W'
    self.type_osc.action = self.change_osc
    self.add_subview(self.type_osc)

  def change_osc(self, sender):
    val = int(sender.value * self.type_len)
    self.toneGenerator = self.osc.wave_types[val]
    self.type_osc.value = val / self.type_len

  def setup_frq_slider(self):
    self.max_level_frq = 880.0
    self.level_frq = ui.Slider()
    self.level_frq.value = self.osc.frequency / self.max_level_frq
    self.level_frq.flex = 'W'
    self.level_frq.action = self.change_frq
    self.add_subview(self.level_frq)

  def change_frq(self, sender):
    val = sender.value * self.max_level_frq
    self.osc.frequency = val

  def layout(self):
    self.level_frq.y = self.type_osc.height

  def will_close(self):
    self.synth.stop()


if __name__ == '__main__':
  view = View()
  #view.present()
  # ã‚¹ãƒ©ã‚¤ãƒ€ãƒ¼æ“ä½œæ™‚ã«View ãŒå‹•ã„ã¦ã—ã¾ã†ãŸã‚
  view.present(style='fullscreen', orientations=['portrait'])

```

## éŸ³å£°æƒ…å ±ã®å¯è¦–åŒ–

ã“ã“ã¾ã§ãã‚‹ã¨ã€View ä¸Šéƒ¨ã«ã‚¹ãƒ©ã‚¤ãƒ€ãƒ¼ 2 æœ¬ã®ã¿ã€‚ã¨ã„ã†è¦‹ãŸç›®ãŒå¯‚ã—ããªã£ã¦ãã¾ã—ãŸã€‚

ï¼ˆGIF ã§ã‚‚ã€åŒã˜çµµã§æŠ¼ã—é€šã›ãªããªã£ã¦ã„ã¾ã™ï¼‰

[AVAudioEngine ã‚’ä½¿ã£ã¦éŸ³å£°ã«ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã«ã‚¨ãƒ•ã‚§ã‚¯ãƒˆã‚’ã‹ã‘ã¦ä¿å­˜ã™ã‚‹æ–¹æ³•(ã‚µãƒ³ãƒ—ãƒ«ã‚ã‚Š) - Qiita](https://qiita.com/ahiru___/items/2233c23a0e8070d265ea)

https://qiita.com/ahiru___/items/2233c23a0e8070d265ea

render ã¨ã—ã¦è‡ªä½œã—ãŸ`block`ï¼ˆ`source_node_render`ï¼‰ã®éŸ³ã«ãªã‚‹æƒ…å ±ã‚’ã€åˆ¥ã®`block` ã‚’ä½œã‚‹ã“ã¨ã§å–å¾—ãŒã§ããã†ã§ã™ã€‚

[installTapOnBus:bufferSize:format:block: | Apple Developer Documentation](https://developer.apple.com/documentation/avfaudio/avaudionode/1387122-installtaponbus)

https://developer.apple.com/documentation/avfaudio/avaudionode/1387122-installtaponbus

`tap_block` ã¨ã—ã¦ã€`ObjCBlock` ã‚’å®šç¾©ã—ã¾ã™:

```py
self.tap_block = ObjCBlock(
  self.audio_node_tap,
  restype=None,
  argtypes=[
    ctypes.c_void_p,
    ctypes.c_void_p,
    ctypes.c_void_p,
  ])
```

ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯é–¢æ•°ã¨ã—ã¦ã€`audio_node_tap` ã‚’ã¤ãã‚Šã¾ã™:

```py
def audio_node_tap(self, _cmd, buffer, when):
  # objc_util ã®å‡¦ç†
  buf = ObjCInstance(buffer)
  _array = buf.floatChannelData()[0]

  # ã“ã“ã‹ã‚‰Python ã®å‡¦ç†
  # ç”»åƒç”Ÿæˆç”¨ã«é…åˆ—çµ„ã¿æ›¿ãˆ
  np_buff = np.ctypeslib.as_array(_array, (256, 16))
  with BytesIO() as bIO:
    matplotlib.image.imsave(bIO, np_buff + 1, format='png')
    img = ui.Image.from_data(bIO.getvalue())
    self.parent.visualize_view.image = img
```

`objc_util` ã§è€ƒãˆã‚‹ã“ã¨ã¨ã€Pythonï¼ˆPythonista3ï¼‰ã§è€ƒãˆã‚‹ã“ã¨ã‚’åˆ†ã‘ã¦ã€æ··ä¹±ã™ã‚‹è¦å› ã‚’æ¸›ã‚‰ã—ã¾ã™ã€‚

å…ˆã«`objc_util` ã®å‡¦ç†ã‚’é€²ã‚ã¾ã™ã€‚

### `objc_util` ã®å‡¦ç†

`Synth` å†…ã®ã€connect å‡¦ç†ã‚’ã—ã¦ã„ã‚‹æœ€çµ‚ç‚¹ã® `mainMixer` ã‹ã‚‰å–å¾—ã‚’ã—ã¾ã™ã€‚

ï¼ˆæ•°å¼ã§ç”Ÿæˆã—ãŸæƒ…å ±ã‚’å–ã‚ŠãŸã„å ´åˆã«ã¯`sourceNode`ï¼‰

```py
audioEngine.connect_to_format_(mainMixer, outputNode, inputFormat)
audioEngine.prepare()

_bufsize = 64 * 64  # å–å¾—ã™ã‚‹æƒ…å ±é‡
mainMixer.installTapOnBus_bufferSize_format_block_(
  0, _bufsize, inputFormat, self.tap_block)
self.audioEngine = audioEngine
```

`_bufsize` ã«ã¦ã€å–ã‚ŠãŸã„ã‚µã‚¤ã‚ºæŒ‡å®šã‚’ã—ã¾ã™ã€‚ç„¡é§„ã«å¤šãã¦ã‚‚å‡¦ç†ãŒè¿½ã„ã¤ã‹ãªã„å¯èƒ½æ€§ãŒã‚ã‚‹ã®ã§ã€`4096 = 64*64` ã¨ã—ã¾ã—ãŸã€‚

`installTapOnBus_bufferSize_format_block_` ã«ã¦ã€`audio_node_tap` ãŒå‘¼ã³å‡ºã•ã‚Œã‚‹ã‚ˆã†ã«ãªã‚Šã¾ã—ãŸã€‚

```py
def audio_node_tap(self, _cmd, buffer, when):
  # objc_util ã®å‡¦ç†
  buf = ObjCInstance(buffer)
  _array = buf.floatChannelData()[0]
```

å‹å®šç¾©ã‚’äº‹ç´°ã‹ãèª¬æ˜ã—ã¦ã„ã¾ã—ãŸãŒã€`objc_util.ObjCInstance` ã§å•é¡Œãªã„ã®ã§ã‚ã‚Œã°`ctypes.c_void_p` ã§å®šç¾©ã—ã¦ã—ã¾ã£ã¦ã„ã¾ã™ã€‚

`ObjCInstance` ã§å•é¡Œãªã„ãªã‚‰ã€ãã‚Œã¯ãã‚Œã§ã‚ªãƒƒã‚±ãƒ¼çš„ãªè€ƒãˆæ–¹ã§ã™ï¼ˆé›‘ï¼‰ã€‚

`floatChannelData()` ã¯ã€é…åˆ—ã§æ¥ã‚‹ã®ã§ index ã®`[0]` ã§æƒ…å ±ã‚’è²°ã„ã¾ã™ã€‚

`block` ã¯ã€æ¯å›ã™ã”ã„æ—©ã•ã§å‘¼ã³å‡ºã•ã‚Œã‚‹ã®ã§ã€`print` ç¢ºèªãŒå¤§å¤‰ã§ã™ã€‚

å®Ÿè¡Œå¾Œã«å³çµ‚äº†ã•ã›ã¦`print` å‡ºåŠ›é‡ã‚’æ¸›ã‚‰ã—ã€å¿…è¦ãªæƒ…å ±ã‚’ç¢ºèªã™ã‚‹ä½œæ¥­ã‚’ã—ã¦ã„ã¾ã™ï¼ˆã‚‚ã¡ã‚ã‚“äº‹å‰ã« Documentation ã§è¿”ã£ã¦ãã‚‹å†…å®¹ã‚’æŠŠæ¡ã™ã‚‹ã“ã¨ã‚‚å¤§äº‹ã§ã™ï¼‰ã€‚

éŸ³ãƒ‡ãƒ¼ã‚¿ã®å†…éƒ¨æ§‹é€ ãªã©ã€ã‚ã¡ã‚ƒãã¡ã‚ƒé¢ç™½ãæ·±ã„ã®ã§ã™ãŒã€é•·ããªã‚Šãã†ãªã®ã§æ³£ãæ³£ãå‰²æ„›ã—ã¾ã™ã€‚ã€‚ã€‚

#### Python ã®å‡¦ç†

`audio_node_tap` ãƒ¡ã‚½ãƒƒãƒ‰ã«ã¦ã€Objective-Cï¼ˆ`objc_util`ï¼‰ã®æƒ…å ±ã‚’ã€é€šå¸¸ã® Python ã§å‡¦ç†ã§ãã‚‹ã‚ˆã†ã«ãªã‚Šã¾ã—ãŸã€‚

ã–ã£ãã‚Šã¨ã—ãŸèª¬æ˜ã§ã™ã¨ã€PCM ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã®éŸ³ã®æƒ…å ±ï¼ˆ`-1.0 ã€œ 1.0`ï¼‰ãŒé…åˆ—ã¨ã—ã¦å…¥ã£ã¦ã„ã¾ã™ã€‚

æœ€çµ‚çš„ã«`ui.Image` ã¸ä¹—ã›ãŸã„ã®ã§ã€ãƒã‚¤ãƒˆåˆ—ã®ç”»åƒæƒ…å ±ã«å¤‰æ›ã‚’ã•ã›ãŸã„ã®ã§ã™ã€‚

:::note warn
ã“ã“ã‹ã‚‰ã® Python å‡¦ç†
å½“æ™‚ã©ã®ã‚ˆã†ã«èª¿ã¹å®Ÿè£…ã—ãŸã®ã‹ã®è¨˜éŒ²ãŒãªã
ã‚†ã‚‹ãµã‚ãªã€èª¬æ˜ã«ãªã£ã¦ã—ã¾ã„ã¾ã™ ğŸ™‡
:::

##### NumPy ã§é…åˆ—ã‚’æ•´ãˆã‚‹

é…åˆ—ã®å½¢çŠ¶ã‚’å¤‰æ›´ã•ã›ã‚‹ã®ã¯ã€NumPy ãŒå¼·ã„ã®ã§ï¼ˆã—ã‹ã‚‚`ctypes` çµŒç”±ã®æ“ä½œãªã®ã§ï¼‰ã€`np.ctypeslib.as_array` ã§å½¢çŠ¶ã‚’æ•´ãˆã¾ã™ã€‚

æœ€çµ‚å‡ºåŠ›ç”»åƒã‚’ç¢ºèªã—ãªãŒã‚‰ã®èª¿æ•´ã§ã™ãŒã€`4096 = (256, 16)` ãŒç¶ºéº—ãªæ¨ªä¸¦ã³ã¨ãªã£ãŸã®ã§ã€ãã®ã‚ˆã†ãªæ•°å€¤ã¨ã—ã¦ã„ã¾ã™ã€‚

##### Matplotlib ã§ç”»åƒã‚’ä½œã‚‹

Matplotlib ã§ã‚°ãƒ©ãƒ•ã¯ä½œã‚Šã¾ã›ã‚“ã€‚

ï¼ˆã‹ã¤ã¦ï¼‰éŸ³ãƒ‡ãƒ¼ã‚¿ã ã£ãŸé…åˆ—ã‚’ã€ãƒã‚¤ãƒˆãƒ‡ãƒ¼ã‚¿ã¨ã—ã¦ç”»åƒåŒ–ã—ã¾ã™ã€‚

```py
np_buff = np.ctypeslib.as_array(_array, (256, 16))
with BytesIO() as bIO:
  matplotlib.image.imsave(bIO, np_buff + 1, format='png')
  img = ui.Image.from_data(bIO.getvalue())

```

`PIL` ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã§ã‚‚ã„ã„æ°—ãŒã—ã¾ã™ãŒã€ãªãœã‹ Matplotlib ã‚’ä½¿ã£ã¦ã„ã‚‹ç†ç”±ã¯ä¸æ˜ã§ã™ã€‚ã€‚ã€‚

[Python Imaging Library â€” Python 3.6.1 documentation](https://omz-software.com/pythonista/docs/ios/PIL.html)

https://omz-software.com/pythonista/docs/ios/PIL.html

Matplotlib ã®æ–¹ãŒå½“æ™‚ã‚„ã‚Šã‚„ã™ã‹ã£ãŸã®ã‹ã‚‚ã—ã‚Œã¾ã›ã‚“ã€‚

ä½¿ã„ã‚„ã™ã„ã€ã‚„ã‚Šã‚„ã™ã„æ–¹æ³•ã§å®Ÿè£…ã„ãŸã ã„ã¦å•é¡Œã‚ã‚Šã¾ã›ã‚“ã€‚

å¤‰æ•°`img` ã¨ã—ã¦ã€`ui.Image` ã«ä¹—ã›ã‚‰ã‚Œã‚‹çŠ¶æ…‹ã«ãªã‚Šã¾ã—ãŸã€‚

### `ui.View` ã§ã®å¯è¦–åŒ–

æœ€çµ‚å‡ºåŠ›ã¨ãªã‚‹éŸ³ãƒ‡ãƒ¼ã‚¿ã‚’æŠœãå‡ºã—ã€ç”»åƒæƒ…å ±ã«å¤‰ã‚ã‚‹ã‚ˆã†é…åˆ—ã‚’æ•´å½¢ã—`ui.Image` ã¨ã—ã¦`img` ã®æº–å‚™ã¾ã§å®Œäº†ã—ã¾ã—ãŸã€‚

class ã®`View` ã¸ã€ä¹—ã›ãŸã„ã‚‚ã®ã‚’ä¹—ã›ã¦ã„ãã¾ã—ã‚‡ã†:

```py
from math import sin, pi
from random import uniform
import ctypes
from io import BytesIO

import numpy as np
import matplotlib.image

from objc_util import ObjCClass, ObjCInstance, ObjCBlock
import ui

import pdbg

CHANNEL = 1

OSStatus = ctypes.c_int32

AVAudioEngine = ObjCClass('AVAudioEngine')
AVAudioSourceNode = ObjCClass('AVAudioSourceNode')
AVAudioFormat = ObjCClass('AVAudioFormat')


class AudioBuffer(ctypes.Structure):
  _fields_ = [
    ('mNumberChannels', ctypes.c_uint32),
    ('mDataByteSize', ctypes.c_uint32),
    ('mData', ctypes.c_void_p),
  ]


class AudioBufferList(ctypes.Structure):
  _fields_ = [
    ('mNumberBuffers', ctypes.c_uint32),
    ('mBuffers', AudioBuffer * CHANNEL),
  ]


class Oscillator:
  def __init__(self):
    self.amplitude: float = 1.0
    self.frequency: float = 440.0
    self.wave_types = [
      self.sine,
      self.triangle,
      self.sawtooth,
      self.square,
      self.white_noise,
    ]

  def sine(self, time):
    wave = self.amplitude * sin(2.0 * pi * self.frequency * time)
    return wave

  def triangle(self, time):
    period = 1.0 / self.frequency
    currentTime = time % period
    value = currentTime / period
    result = 0.0
    if value < 0.25:
      result = value * 4
    elif value < 0.75:
      result = 2.0 - (value * 4.0)
    else:
      result = value * 4 - 4.0
    wave = self.amplitude * result
    return wave

  def sawtooth(self, time):
    period = 1.0 / self.frequency
    currentTime = time % period
    wave = self.amplitude * ((currentTime / period) * 2 - 1.0)
    return wave

  def square(self, time):
    period = 1.0 / self.frequency
    currentTime = time % period
    if (currentTime / period) < 0.5:
      wave = self.amplitude
    else:
      wave = -1.0 * self.amplitude
    return wave

  def white_noise(self, _):
    return uniform(-1.0, 1.0)


class Synth:
  def __init__(self, parent):
    self.parent: ui.View = parent  # è¦ªã¨ãªã‚‹ui.View
    self.audioEngine: AVAudioEngine
    self.sampleRate: float = 44100.0  # set_up ãƒ¡ã‚½ãƒƒãƒ‰: outputNode ã‚ˆã‚Šç¢ºå®š
    self.deltaTime: float = 0.0  # 1/sampleRate æ™‚é–“é–“éš”
    self.timex: float = 0.0  # Render ã®é–“éš”ã‚«ã‚¦ãƒ³ã‚¿ãƒ¼

    self.render_block = ObjCBlock(
      self.source_node_render,
      restype=OSStatus,
      argtypes=[
        ctypes.c_void_p, ctypes.c_void_p, ctypes.c_void_p, ctypes.c_void_p,
        ctypes.POINTER(AudioBufferList)
      ])

    self.tap_block = ObjCBlock(
      self.audio_node_tap,
      restype=None,
      argtypes=[
        ctypes.c_void_p,
        ctypes.c_void_p,
        ctypes.c_void_p,
      ])

    self.set_up()

  def set_up(self):
    audioEngine = AVAudioEngine.new()
    sourceNode = AVAudioSourceNode.alloc()
    mainMixer = audioEngine.mainMixerNode()
    outputNode = audioEngine.outputNode()
    format = outputNode.inputFormatForBus_(0)

    self.sampleRate = format.sampleRate()
    self.deltaTime = 1 / self.sampleRate

    inputFormat = AVAudioFormat.alloc(
    ).initWithCommonFormat_sampleRate_channels_interleaved_(
      format.commonFormat(), self.sampleRate, CHANNEL, format.isInterleaved())

    sourceNode.initWithFormat_renderBlock_(inputFormat, self.render_block)

    audioEngine.attachNode_(sourceNode)
    sourceNode.volume = 0.1

    audioEngine.connect_to_format_(sourceNode, mainMixer, inputFormat)
    audioEngine.connect_to_format_(mainMixer, outputNode, inputFormat)

    audioEngine.prepare()

    _bufsize = 64 * 64  # å–å¾—ã™ã‚‹æƒ…å ±é‡
    mainMixer.installTapOnBus_bufferSize_format_block_(
      0, _bufsize, inputFormat, self.tap_block)
    self.audioEngine = audioEngine

  def source_node_render(self,
                         _cmd: ctypes.c_void_p,
                         _isSilence_ptr: ctypes.c_void_p,
                         _timestamp_ptr: ctypes.c_void_p,
                         frameCount: ctypes.c_void_p,
                         outputData_ptr: ctypes.POINTER) -> OSStatus:
    ablPointer = outputData_ptr.contents
    for frame in range(frameCount):
      sampleVal = self.parent.toneGenerator(self.timex)

      self.timex += self.deltaTime

      for bufferr in range(ablPointer.mNumberBuffers):
        _mData = ablPointer.mBuffers[bufferr].mData
        _pointer = ctypes.POINTER(ctypes.c_float * frameCount)
        buffer = ctypes.cast(_mData, _pointer).contents
        buffer[frame] = sampleVal
    return 0

  def audio_node_tap(self, _cmd, buffer, when):
    buf = ObjCInstance(buffer)
    _array = buf.floatChannelData()[0]
    # ç”»åƒç”Ÿæˆç”¨ã«é…åˆ—çµ„ã¿æ›¿ãˆ
    np_buff = np.ctypeslib.as_array(_array, (256, 16))
    with BytesIO() as bIO:
      matplotlib.image.imsave(bIO, np_buff + 1, format='png')
      img = ui.Image.from_data(bIO.getvalue())
      self.parent.visualize_view.image = img

  def start(self):
    self.audioEngine.startAndReturnError_(None)

  def stop(self):
    self.audioEngine.stop()


class View(ui.View):
  def __init__(self, *args, **kwargs):
    ui.View.__init__(self, *args, **kwargs)

    self.visualize_view = ui.ImageView()
    self.visualize_view.bg_color = 0
    self.visualize_view.flex = 'WH'
    self.add_subview(self.visualize_view)

    self.type_osc = ui.Slider()
    self.level_frq = ui.Slider()
    self.osc_log = ui.Label()
    self.frq_log = ui.Label()

    self.osc = Oscillator()
    self.toneGenerator: Oscillator
    self.setup_osc()

    self.synth = Synth(self)
    self.synth.start()

  def setup_osc(self):
    self.toneGenerator = self.osc.wave_types[0]
    self.setup_type_osc()
    self.setup_frq_level()

  def setup_type_osc(self):
    # --- slider
    self.type_len = len(self.osc.wave_types) - 1
    self.type_osc.continuous = False
    self.type_osc.value = 0
    self.type_osc.flex = 'W'
    self.type_osc.action = self.change_osc
    self.add_subview(self.type_osc)

    # --- label
    self.osc_log.text = self.toneGenerator.__name__
    self.osc_log.bg_color = 1
    self.osc_log.flex = 'W'
    self.osc_log.size_to_fit()
    self.add_subview(self.osc_log)

  def change_osc(self, sender):
    val = int(sender.value * self.type_len)
    self.toneGenerator = self.osc.wave_types[val]
    self.type_osc.value = val / self.type_len
    self.osc_log.text = self.toneGenerator.__name__

  def setup_frq_level(self):
    # --- slider
    self.max_level_frq = 880.0
    self.level_frq.value = self.osc.frequency / self.max_level_frq
    self.level_frq.flex = 'W'
    self.level_frq.action = self.change_frq
    self.add_subview(self.level_frq)

    # --- label
    self.frq_log.text = f'{self.osc.frequency}'
    self.frq_log.bg_color = 1
    self.frq_log.flex = 'W'
    self.frq_log.size_to_fit()
    self.add_subview(self.frq_log)

  def change_frq(self, sender):
    val = sender.value * self.max_level_frq
    self.osc.frequency = val
    self.frq_log.text = f'{self.osc.frequency}'

  def layout(self):
    # --- slider
    self.type_osc.y = self.type_osc.height
    self.level_frq.y = self.type_osc.height + self.type_osc.y * 2

    # --- label
    self.osc_log.y = self.frame.height / 2 - self.osc_log.height
    self.frq_log.y = self.osc_log.y + self.frq_log.height

    logs_width = self.frame.width / 2
    self.osc_log.width = self.frq_log.width = logs_width

  def will_close(self):
    self.synth.stop()


if __name__ == '__main__':
  view = View()
  #view.present()
  # ã‚¹ãƒ©ã‚¤ãƒ€ãƒ¼æ“ä½œæ™‚ã«View ãŒå‹•ã„ã¦ã—ã¾ã†ãŸã‚
  view.present(style='fullscreen', orientations=['portrait'])

```

![img221206_155006.gif](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/2953777/5aeb1ca5-f274-aaae-673a-20a901e3c29e.gif)

ã‹ãªã‚Š fat ãª`View` class ã¨ãªã£ã¦ã—ã¾ã„ã¾ã—ãŸã€ã€ã€

- éŸ³å£°æƒ…å ±ã®å¯è¦–åŒ–
  - `self.visualize_view`
- osc é–¢ä¿‚
  - æ“ä½œ
    - `self.type_osc`
  - è¡¨ç¤º
    - `self.osc_log`
- å‘¨æ³¢æ•°ï¼ˆ`frequency`ï¼‰é–¢ä¿‚
  - æ“ä½œ
    - `self.level_frq`
  - è¡¨ç¤º
    - `self.frq_log`

View ã®ç”»åƒã®æŸ„ã«ã‚ˆã‚Šã€æ³¢å½¢ã®ç‰¹å¾´ãŒã‚ã‹ã‚Šã¾ã™ã€‚

![img221206_155705.gif](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/2953777/4067c238-217d-c3dd-d29b-812fea1a1cc4.gif)

```
èµ¤ â†’ é»„ â†’ ç·‘ â†’ é’
```

ã®ã€è‰²ã®ç§»ã‚Šå¤‰ã‚ã‚Šã§æ•°å€¤ã®å¼·å¼±ãŒå‡ºåŠ›ã•ã‚Œã¦ã„ã‚‹ã¨ã‚¤ãƒ¡ãƒ¼ã‚¸ã™ã‚‹ã¨ã‚ã‹ã‚Šã‚„ã™ã„ã§ã™ã€‚

#### æ­£å¼¦æ³¢: sine

![img221206_155858.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/2953777/9db8851c-8db7-f874-b612-b86f7c30786c.png)

ç¶ºéº—ã«æ³¢æ‰“ã¤æ³¢å½¢ã«ãªã‚‹ã®ã§ã€ã‚°ãƒ©ãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ã®å¤‰åŒ–ãŒæ»‘ã‚‰ã‹ã«å‡ºã¦ã„ã¾ã™ã€‚

#### ä¸‰è§’æ³¢: triangle

![img221206_155909.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/2953777/cc7c4652-51ee-4d3c-3baa-590a73212c38.png)

ä¸‹ã‹ã‚‰ä¸Šã¸ç›´ç·šã«`â–³` å‹¾é…ã—ã¦ã„ã‚‹çŠ¶æ…‹ã§ã™ã€‚

#### ãƒã‚³ã‚®ãƒªæ³¢: sawtooth

![img221206_155917.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/2953777/ec15adf6-ab0f-fbd9-b035-3be449f476ca.png)

`|\` ã®å‹¾é…ã¨ãªã‚‹ã®ã§ã€`é’` ã‹ã‚‰çªç„¶`èµ¤` ã«ãªã£ã¦ã„ã‚‹ã®ãŒç¢ºèªã§ãã¾ã™ã€‚

#### çŸ©å½¢æ³¢: square

![img221206_155926.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/2953777/7b8b81f6-5dd3-bd83-ee2f-5a31422ffd05.png)

`_| Ì„|_` ã¨ã€ä¸Šä¸‹é–“ã‚’ç›´è§’ã«å¤‰åŒ–ã•ã›ã‚‹ã®ã§ã€`é’` ã¨`èµ¤` ã—ã‹å‡ºã¦ã„ã¾ã›ã‚“ã€‚

#### ãƒã‚¤ã‚º: WhiteNoise

![img221206_155940.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/2953777/2dc1e9e9-24e8-7a7e-b2a0-4d0aa5dd916a.png)

`-1.0 ã€œ 1.0` ã‚’ãƒ©ãƒ³ãƒ€ãƒ ã§å¤‰åŒ–ã•ã›ã¦ã„ã‚‹ã®ã§ã€çµ±ä¸€æ€§ãŒãªãã‚«ãƒ©ãƒ•ãƒ«ã«å‡ºåŠ›ã•ã‚Œã¦ã„ã¾ã™ã€‚

## ä½œæ›²ç·¨æ›²ï¼ï¼Ÿæ³¢å½¢ã‚’ã„ã˜ã£ã¦ã¿ã‚ˆã†

æ³¢å½¢åŒå£«ã‚’çµ„ã¿åˆã‚ã›ã‚‹ã“ã¨ã§ã€å®šå‹ã®æ³¢å½¢ã‹ã‚‰å¤‰åŒ–ã•ã›ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚

`Oscillator` class ã®ä¸­èº«ã‚’ä¸€éƒ¨æ”¹å¤‰ã—ã¦ã€ç‹¬è‡ªã®æ³¢å½¢ã‚’éŸ³ã¨ã—ã¦å‡ºåŠ›ã—ã¦ã¿ã¾ã—ã‚‡ã†ã€‚

å¤‰åŒ–ãŒã‚­ãƒ„ã„ä¸‰è§’æ³¢ã¨ã€æ³¢å½¢ã‚’æ··ãœåˆã‚ã›ã‚‹ãƒ¡ã‚½ãƒƒãƒ‰ã‚’ã¤ãã‚Šã¾ã—ãŸ:

```py
def tone_triangle(self, time, frq=None):
  frequency = frq if frq else self.frequency
  period = 1.0 / frequency
  currentTime = time % period
  value = currentTime / period
  result = 0.0
  if value < 0.0:
    result = value * 4
  elif value > 0.8:
    result = value * 4 - 4.0
  else:
    result = 0
  wave = self.amplitude * result
  return wave

def mixwave(self, time):
  _step = 3 + int(sin(pi * time) * 10)
  steps = _step if _step else 1
  wave01 = self.square(time) * self.tone_triangle(time, steps)
  wave02 = self.white_noise(time) * self.tone_triangle(time, 1)
  wave = wave01 + wave02
  return wave
```

å¼•æ•°ã«`frq=None` ã‚’ä»˜ã‘ã¦ã€`self.frequency` ä»¥å¤–ã§ã‚‚`frequency` ã‚’è¨­å®šã§ãã‚‹ã‚ˆã†ã«ã—ã¦ã„ã¾ã™:

```py
def tone_triangle(self, time, frq=None):
  frequency = frq if frq else self.frequency
```

`frq=None` ã¯ä»–ã®é–¢æ•°ã«ã‚‚ã€å®Ÿè£…ã•ã›ã¦ã„ã¾ã™ã€‚

`Oscillator` ã®é…åˆ—ã«ã‚‚ç™»éŒ²ã—ã¦ã‚ã’ã¾ã—ã‚‡ã†:

```py
self.wave_types = [
  self.mixwave,  # new!
  self.sine,
  self.triangle,
  self.sawtooth,
  self.square,
  self.white_noise,
  self.tone_triangle,  # new!
]
```

![img221206_184633.gif](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/2953777/74926e3a-e3bc-0e51-e6de-bef451b98223.gif)

ã‚³ãƒ¼ãƒ‰ä¾‹ã§ã¯ã€ç”»é¢ã®è‰²å¤‰åŒ–ã®ãƒã‚­ãƒã‚­ãŒå¼·ã„ã®ã§ã€å°ã•ãã—ã¦ã„ã¾ã™ã€‚

```py
from math import sin, pi
from random import uniform
import ctypes
from io import BytesIO

import numpy as np
import matplotlib.image

from objc_util import ObjCClass, ObjCInstance, ObjCBlock
import ui

import pdbg

CHANNEL = 1

OSStatus = ctypes.c_int32

AVAudioEngine = ObjCClass('AVAudioEngine')
AVAudioSourceNode = ObjCClass('AVAudioSourceNode')
AVAudioFormat = ObjCClass('AVAudioFormat')


class AudioBuffer(ctypes.Structure):
  _fields_ = [
    ('mNumberChannels', ctypes.c_uint32),
    ('mDataByteSize', ctypes.c_uint32),
    ('mData', ctypes.c_void_p),
  ]


class AudioBufferList(ctypes.Structure):
  _fields_ = [
    ('mNumberBuffers', ctypes.c_uint32),
    ('mBuffers', AudioBuffer * CHANNEL),
  ]


class Oscillator:
  def __init__(self):
    self.amplitude: float = 1.0
    self.frequency: float = 440.0
    self.wave_types = [
      self.mixwave,
      self.sine,
      self.triangle,
      self.sawtooth,
      self.square,
      self.white_noise,
      self.tone_triangle,
    ]

  def sine(self, time, *args):
    frequency = args[0] if args else self.frequency
    wave = self.amplitude * sin(2.0 * pi * frequency * time)
    return wave

  def triangle(self, time, frq=None):
    frequency = frq if frq else self.frequency
    period = 1.0 / frequency
    currentTime = time % period
    value = currentTime / period
    result = 0.0
    if value < 0.25:
      result = value * 4
    elif value < 0.75:
      result = 2.0 - (value * 4.0)
    else:
      result = value * 4 - 4.0
    wave = self.amplitude * result
    return wave

  def sawtooth(self, time, frq=None):
    frequency = frq if frq else self.frequency
    period = 1.0 / frequency
    currentTime = time % period
    wave = self.amplitude * ((currentTime / period) * 2 - 1.0)
    return wave

  def square(self, time, frq=None):
    frequency = frq if frq else self.frequency
    period = 1.0 / frequency
    currentTime = time % period
    if (currentTime / period) < 0.5:
      wave = self.amplitude
    else:
      wave = -1.0 * self.amplitude
    return wave

  def white_noise(self, _, frq=None):
    return uniform(-1.0, 1.0)

  def tone_triangle(self, time, frq=None):
    frequency = frq if frq else self.frequency
    period = 1.0 / frequency
    currentTime = time % period
    value = currentTime / period
    result = 0.0
    if value < 0.0:
      result = value * 4
    elif value > 0.8:
      result = value * 4 - 4.0
    else:
      result = 0
    wave = self.amplitude * result
    return wave

  def mixwave(self, time):
    _step = 3 + int(sin(pi * time) * 10)
    steps = _step if _step else 1
    wave01 = self.square(time) * self.tone_triangle(time, steps)
    wave02 = self.white_noise(time) * self.tone_triangle(time, 1)
    wave = wave01 + wave02
    return wave


class Synth:
  def __init__(self, parent):
    self.parent: ui.View = parent  # è¦ªã¨ãªã‚‹ui.View
    self.audioEngine: AVAudioEngine
    self.sampleRate: float = 44100.0  # set_up ãƒ¡ã‚½ãƒƒãƒ‰: outputNode ã‚ˆã‚Šç¢ºå®š
    self.deltaTime: float = 0.0  # 1/sampleRate æ™‚é–“é–“éš”
    self.timex: float = 0.0  # Render ã®é–“éš”ã‚«ã‚¦ãƒ³ã‚¿ãƒ¼

    self.render_block = ObjCBlock(
      self.source_node_render,
      restype=OSStatus,
      argtypes=[
        ctypes.c_void_p, ctypes.c_void_p, ctypes.c_void_p, ctypes.c_void_p,
        ctypes.POINTER(AudioBufferList)
      ])

    self.tap_block = ObjCBlock(
      self.audio_node_tap,
      restype=None,
      argtypes=[
        ctypes.c_void_p,
        ctypes.c_void_p,
        ctypes.c_void_p,
      ])

    self.set_up()

  def set_up(self):
    audioEngine = AVAudioEngine.new()
    sourceNode = AVAudioSourceNode.alloc()
    mainMixer = audioEngine.mainMixerNode()
    outputNode = audioEngine.outputNode()
    format = outputNode.inputFormatForBus_(0)

    self.sampleRate = format.sampleRate()
    self.deltaTime = 1 / self.sampleRate

    inputFormat = AVAudioFormat.alloc(
    ).initWithCommonFormat_sampleRate_channels_interleaved_(
      format.commonFormat(), self.sampleRate, CHANNEL, format.isInterleaved())

    sourceNode.initWithFormat_renderBlock_(inputFormat, self.render_block)

    audioEngine.attachNode_(sourceNode)
    sourceNode.volume = 0.1

    audioEngine.connect_to_format_(sourceNode, mainMixer, inputFormat)
    audioEngine.connect_to_format_(mainMixer, outputNode, inputFormat)

    audioEngine.prepare()

    _bufsize = 64 * 64  # å–å¾—ã™ã‚‹æƒ…å ±é‡
    mainMixer.installTapOnBus_bufferSize_format_block_(
      0, _bufsize, inputFormat, self.tap_block)
    self.audioEngine = audioEngine

  def source_node_render(self,
                         _cmd: ctypes.c_void_p,
                         _isSilence_ptr: ctypes.c_void_p,
                         _timestamp_ptr: ctypes.c_void_p,
                         frameCount: ctypes.c_void_p,
                         outputData_ptr: ctypes.POINTER) -> OSStatus:
    ablPointer = outputData_ptr.contents
    for frame in range(frameCount):
      sampleVal = self.parent.toneGenerator(self.timex)

      self.timex += self.deltaTime

      for bufferr in range(ablPointer.mNumberBuffers):
        _mData = ablPointer.mBuffers[bufferr].mData
        _pointer = ctypes.POINTER(ctypes.c_float * frameCount)
        buffer = ctypes.cast(_mData, _pointer).contents
        buffer[frame] = sampleVal
    return 0

  def audio_node_tap(self, _cmd, buffer, when):
    buf = ObjCInstance(buffer)
    _array = buf.floatChannelData()[0]
    # ç”»åƒç”Ÿæˆç”¨ã«é…åˆ—çµ„ã¿æ›¿ãˆ
    np_buff = np.ctypeslib.as_array(_array, (256, 16))
    with BytesIO() as bIO:
      matplotlib.image.imsave(bIO, np_buff + 1, format='png')
      img = ui.Image.from_data(bIO.getvalue())
      self.parent.visualize_view.image = img

  def start(self):
    self.audioEngine.startAndReturnError_(None)

  def stop(self):
    self.audioEngine.stop()


class View(ui.View):
  def __init__(self, *args, **kwargs):
    ui.View.__init__(self, *args, **kwargs)

    self.visualize_view = ui.ImageView()
    self.visualize_view.bg_color = 0
    #self.visualize_view.flex = 'WH'
    self.visualize_view.flex = 'TBRL'
    self.add_subview(self.visualize_view)

    self.type_osc = ui.Slider()
    self.level_frq = ui.Slider()
    self.osc_log = ui.Label()
    self.frq_log = ui.Label()

    self.osc = Oscillator()
    self.toneGenerator: Oscillator
    self.setup_osc()

    self.synth = Synth(self)
    self.synth.start()

  def setup_osc(self):
    self.toneGenerator = self.osc.wave_types[0]
    self.setup_type_osc()
    self.setup_frq_level()

  def setup_type_osc(self):
    # --- slider
    self.type_len = len(self.osc.wave_types) - 1
    self.type_osc.continuous = False
    self.type_osc.value = 0
    self.type_osc.flex = 'W'
    self.type_osc.action = self.change_osc
    self.add_subview(self.type_osc)

    # --- label
    self.osc_log.text = self.toneGenerator.__name__
    self.osc_log.bg_color = 1
    self.osc_log.flex = 'W'
    self.osc_log.size_to_fit()
    self.add_subview(self.osc_log)

  def change_osc(self, sender):
    val = int(sender.value * self.type_len)
    self.toneGenerator = self.osc.wave_types[val]
    self.type_osc.value = val / self.type_len
    self.osc_log.text = self.toneGenerator.__name__

  def setup_frq_level(self):
    # --- slider
    self.max_level_frq = 880.0
    self.level_frq.value = self.osc.frequency / self.max_level_frq
    self.level_frq.flex = 'W'
    self.level_frq.action = self.change_frq
    self.add_subview(self.level_frq)

    # --- label
    self.frq_log.text = f'{self.osc.frequency}'
    self.frq_log.bg_color = 1
    self.frq_log.flex = 'W'
    self.frq_log.size_to_fit()
    self.add_subview(self.frq_log)

  def change_frq(self, sender):
    val = sender.value * self.max_level_frq
    self.osc.frequency = val
    self.frq_log.text = f'{self.osc.frequency}'

  def layout(self):
    # --- slider
    self.type_osc.y = self.type_osc.height
    self.level_frq.y = self.type_osc.height + self.type_osc.y * 2

    # --- label
    self.osc_log.y = self.frame.height / 2 - self.osc_log.height
    self.frq_log.y = self.osc_log.y + self.frq_log.height

    logs_width = self.frame.width / 2
    self.osc_log.width = self.frq_log.width = logs_width

  def will_close(self):
    self.synth.stop()


if __name__ == '__main__':
  view = View()
  #view.present()
  # ã‚¹ãƒ©ã‚¤ãƒ€ãƒ¼æ“ä½œæ™‚ã«View ãŒå‹•ã„ã¦ã—ã¾ã†ãŸã‚
  view.present(style='fullscreen', orientations=['portrait'])

```

#### ã‚¨ãƒ•ã‚§ã‚¯ãƒˆã‚’ã¤ã‘ã‚ˆã†

[AVAudioUnitDelay | Apple Developer Documentation](https://developer.apple.com/documentation/avfaudio/avaudiounitdelay?language=objc)

https://developer.apple.com/documentation/avfaudio/avaudiounitdelay?language=objc

[AVAudioUnit ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿è©³ç´°ï¼ˆåŸºæœ¬ç·¨ï¼‰ - Qiita](https://qiita.com/MJeeeey/items/e5dc75b20adb59c7d48f)

https://qiita.com/MJeeeey/items/e5dc75b20adb59c7d48f

AudioUnit ã®ã‚¨ãƒ•ã‚§ã‚¯ãƒˆãŒä½¿ãˆã¾ã™ï¼

å‘¼ã³å‡ºã—ã¯ç°¡å˜ã§:

```py
AVAudioUnitDelay = ObjCClass('AVAudioUnitDelay')

delay = AVAudioUnitDelay.new()
delay.delayTime = 0.3
delay.feedback = 80
```

ã‚¢ã‚¿ãƒƒãƒã—ã¦ã€Node ã« connect ã™ã‚Œã°ã€åæ˜ ã•ã‚Œã¾ã™:

```py
audioEngine.attachNode_(delay)

audioEngine.connect_to_format_(sourceNode, delay, inputFormat)
audioEngine.connect_to_format_(delay, mainMixer, inputFormat)

```

éŸ³ãŒã‚«ã‚ªã‚¹ãªã®ã§ã€ã‚¨ãƒ•ã‚§ã‚¯ãƒˆãŒã‚ã‹ã‚Šã«ãã„ã‹ã‚‚ã—ã‚Œã¾ã›ã‚“ãŒã€ç„¡äº‹ã«ã‹ã‹ã£ã¦ã„ã¾ã™ã­ï¼

osc ã®åˆ‡ã‚Šæ›¿ãˆã‚„å‘¨æ³¢æ•°å¤‰æ›´æ™‚ãŒã€ã‚ã‹ã‚Šã‚„ã™ã„ã‹ã‚‚ã—ã‚Œã¾ã›ã‚“ã€‚

```py
from math import sin, pi
from random import uniform
import ctypes
from io import BytesIO

import numpy as np
import matplotlib.image

from objc_util import ObjCClass, ObjCInstance, ObjCBlock
import ui

import pdbg

CHANNEL = 1

OSStatus = ctypes.c_int32

AVAudioEngine = ObjCClass('AVAudioEngine')
AVAudioSourceNode = ObjCClass('AVAudioSourceNode')
AVAudioFormat = ObjCClass('AVAudioFormat')
AVAudioUnitDelay = ObjCClass('AVAudioUnitDelay')


class AudioBuffer(ctypes.Structure):
  _fields_ = [
    ('mNumberChannels', ctypes.c_uint32),
    ('mDataByteSize', ctypes.c_uint32),
    ('mData', ctypes.c_void_p),
  ]


class AudioBufferList(ctypes.Structure):
  _fields_ = [
    ('mNumberBuffers', ctypes.c_uint32),
    ('mBuffers', AudioBuffer * CHANNEL),
  ]


class Oscillator:
  def __init__(self):
    self.amplitude: float = 1.0
    self.frequency: float = 440.0
    self.wave_types = [
      self.mixwave,
      self.sine,
      self.triangle,
      self.sawtooth,
      self.square,
      self.white_noise,
      self.tone_triangle,
    ]

  def sine(self, time, *args):
    frequency = args[0] if args else self.frequency
    wave = self.amplitude * sin(2.0 * pi * frequency * time)
    return wave

  def triangle(self, time, frq=None):
    frequency = frq if frq else self.frequency
    period = 1.0 / frequency
    currentTime = time % period
    value = currentTime / period
    result = 0.0
    if value < 0.25:
      result = value * 4
    elif value < 0.75:
      result = 2.0 - (value * 4.0)
    else:
      result = value * 4 - 4.0
    wave = self.amplitude * result
    return wave

  def sawtooth(self, time, frq=None):
    frequency = frq if frq else self.frequency
    period = 1.0 / frequency
    currentTime = time % period
    wave = self.amplitude * ((currentTime / period) * 2 - 1.0)
    return wave

  def square(self, time, frq=None):
    frequency = frq if frq else self.frequency
    period = 1.0 / frequency
    currentTime = time % period
    if (currentTime / period) < 0.5:
      wave = self.amplitude
    else:
      wave = -1.0 * self.amplitude
    return wave

  def white_noise(self, _, frq=None):
    return uniform(-1.0, 1.0)

  def tone_triangle(self, time, frq=None):
    frequency = frq if frq else self.frequency
    period = 1.0 / frequency
    currentTime = time % period
    value = currentTime / period
    result = 0.0
    if value < 0.0:
      result = value * 4
    elif value > 0.8:
      result = value * 4 - 4.0
    else:
      result = 0
    wave = self.amplitude * result
    return wave

  def mixwave(self, time):
    _step = 3 + int(sin(pi * time) * 10)
    steps = _step if _step else 1
    wave01 = self.square(time) * self.tone_triangle(time, _step)
    wave02 = self.white_noise(time) * self.tone_triangle(time, 1)
    wave = wave01 + wave02
    return wave


class Synth:
  def __init__(self, parent):
    self.parent: ui.View = parent  # è¦ªã¨ãªã‚‹ui.View
    self.audioEngine: AVAudioEngine
    self.sampleRate: float = 44100.0  # set_up ãƒ¡ã‚½ãƒƒãƒ‰: outputNode ã‚ˆã‚Šç¢ºå®š
    self.deltaTime: float = 0.0  # 1/sampleRate æ™‚é–“é–“éš”
    self.timex: float = 0.0  # Render ã®é–“éš”ã‚«ã‚¦ãƒ³ã‚¿ãƒ¼

    self.render_block = ObjCBlock(
      self.source_node_render,
      restype=OSStatus,
      argtypes=[
        ctypes.c_void_p, ctypes.c_void_p, ctypes.c_void_p, ctypes.c_void_p,
        ctypes.POINTER(AudioBufferList)
      ])

    self.tap_block = ObjCBlock(
      self.audio_node_tap,
      restype=None,
      argtypes=[
        ctypes.c_void_p,
        ctypes.c_void_p,
        ctypes.c_void_p,
      ])

    self.set_up()

  def set_up(self):
    audioEngine = AVAudioEngine.new()
    sourceNode = AVAudioSourceNode.alloc()
    mainMixer = audioEngine.mainMixerNode()
    outputNode = audioEngine.outputNode()
    format = outputNode.inputFormatForBus_(0)

    delay = AVAudioUnitDelay.new()
    delay.delayTime = 0.3
    delay.feedback = 80

    self.sampleRate = format.sampleRate()
    self.deltaTime = 1 / self.sampleRate

    inputFormat = AVAudioFormat.alloc(
    ).initWithCommonFormat_sampleRate_channels_interleaved_(
      format.commonFormat(), self.sampleRate, CHANNEL, format.isInterleaved())

    sourceNode.initWithFormat_renderBlock_(inputFormat, self.render_block)

    audioEngine.attachNode_(sourceNode)
    sourceNode.volume = 0.1

    audioEngine.attachNode_(delay)

    audioEngine.connect_to_format_(sourceNode, delay, inputFormat)
    audioEngine.connect_to_format_(delay, mainMixer, inputFormat)

    audioEngine.connect_to_format_(mainMixer, outputNode, inputFormat)

    audioEngine.prepare()

    _bufsize = 64 * 64  # å–å¾—ã™ã‚‹æƒ…å ±é‡
    mainMixer.installTapOnBus_bufferSize_format_block_(
      0, _bufsize, inputFormat, self.tap_block)
    self.audioEngine = audioEngine

  def source_node_render(self,
                         _cmd: ctypes.c_void_p,
                         _isSilence_ptr: ctypes.c_void_p,
                         _timestamp_ptr: ctypes.c_void_p,
                         frameCount: ctypes.c_void_p,
                         outputData_ptr: ctypes.POINTER) -> OSStatus:
    ablPointer = outputData_ptr.contents
    for frame in range(frameCount):
      sampleVal = self.parent.toneGenerator(self.timex)

      self.timex += self.deltaTime

      for bufferr in range(ablPointer.mNumberBuffers):
        _mData = ablPointer.mBuffers[bufferr].mData
        _pointer = ctypes.POINTER(ctypes.c_float * frameCount)
        buffer = ctypes.cast(_mData, _pointer).contents
        buffer[frame] = sampleVal
    return 0

  def audio_node_tap(self, _cmd, buffer, when):
    buf = ObjCInstance(buffer)
    _array = buf.floatChannelData()[0]
    # ç”»åƒç”Ÿæˆç”¨ã«é…åˆ—çµ„ã¿æ›¿ãˆ
    np_buff = np.ctypeslib.as_array(_array, (256, 16))
    with BytesIO() as bIO:
      matplotlib.image.imsave(bIO, np_buff + 1, format='png')
      img = ui.Image.from_data(bIO.getvalue())
      self.parent.visualize_view.image = img

  def start(self):
    self.audioEngine.startAndReturnError_(None)

  def stop(self):
    self.audioEngine.stop()


class View(ui.View):
  def __init__(self, *args, **kwargs):
    ui.View.__init__(self, *args, **kwargs)

    self.visualize_view = ui.ImageView()
    self.visualize_view.bg_color = 0
    self.visualize_view.flex = 'WH'
    #self.visualize_view.flex = 'TBRL'
    self.add_subview(self.visualize_view)

    self.type_osc = ui.Slider()
    self.level_frq = ui.Slider()
    self.osc_log = ui.Label()
    self.frq_log = ui.Label()

    self.osc = Oscillator()
    self.toneGenerator: Oscillator
    self.setup_osc()

    self.synth = Synth(self)
    self.synth.start()

  def setup_osc(self):
    self.toneGenerator = self.osc.wave_types[0]
    self.setup_type_osc()
    self.setup_frq_level()

  def setup_type_osc(self):
    # --- slider
    self.type_len = len(self.osc.wave_types) - 1
    self.type_osc.continuous = False
    self.type_osc.value = 0
    self.type_osc.flex = 'W'
    self.type_osc.action = self.change_osc
    self.add_subview(self.type_osc)

    # --- label
    self.osc_log.text = self.toneGenerator.__name__
    self.osc_log.bg_color = 1
    self.osc_log.flex = 'W'
    self.osc_log.size_to_fit()
    self.add_subview(self.osc_log)

  def change_osc(self, sender):
    val = int(sender.value * self.type_len)
    self.toneGenerator = self.osc.wave_types[val]
    self.type_osc.value = val / self.type_len
    self.osc_log.text = self.toneGenerator.__name__

  def setup_frq_level(self):
    # --- slider
    self.max_level_frq = 880.0
    self.level_frq.value = self.osc.frequency / self.max_level_frq
    self.level_frq.flex = 'W'
    self.level_frq.action = self.change_frq
    self.add_subview(self.level_frq)

    # --- label
    self.frq_log.text = f'{self.osc.frequency}'
    self.frq_log.bg_color = 1
    self.frq_log.flex = 'W'
    self.frq_log.size_to_fit()
    self.add_subview(self.frq_log)

  def change_frq(self, sender):
    val = sender.value * self.max_level_frq
    self.osc.frequency = val
    self.frq_log.text = f'{self.osc.frequency}'

  def layout(self):
    # --- slider
    self.type_osc.y = self.type_osc.height
    self.level_frq.y = self.type_osc.height + self.type_osc.y * 2

    # --- label
    self.osc_log.y = self.frame.height / 2 - self.osc_log.height
    self.frq_log.y = self.osc_log.y + self.frq_log.height

    logs_width = self.frame.width / 2
    self.osc_log.width = self.frq_log.width = logs_width

  def will_close(self):
    self.synth.stop()


if __name__ == '__main__':
  view = View()
  #view.present()
  # ã‚¹ãƒ©ã‚¤ãƒ€ãƒ¼æ“ä½œæ™‚ã«View ãŒå‹•ã„ã¦ã—ã¾ã†ãŸã‚
  view.present(style='fullscreen', orientations=['portrait'])

```

## å‚è€ƒæ–‡çŒ®

- [ã€iOSã€‘Core Audio ã§ã‚·ãƒ³ã‚»ã‚µã‚¤ã‚¶ãƒ¼ã‚’ä½œã‚‹ - Qiita](https://qiita.com/TokyoYoshida/items/df60ea8585a0223e868b)
- [Building a Synthesizer in Swift. Making audio waveforms withâ€¦ | by SwiftMoji | Better Programming](https://betterprogramming.pub/building-a-synthesizer-in-swift-866cd15b731)
- [Building a Signal Generator | Apple Developer Documentation](https://developer.apple.com/documentation/avfaudio/audio_engine/building_a_signal_generator)
- [AVAudioSourceNode, AVAudioSinkNode or How I Deleted a Repo in Less Than 24 hours](https://orjpap.github.io/swift/real-time/audio/avfoundation/2020/05/19/processAudio.html)

## æ¬¡å›ã¯

2 å›ã«æ¸¡ã‚Šã€`AVAudioSourceNode` ã‚’ä½¿ã£ãŸéŸ³ã®ç”Ÿæˆãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°ã‚’è¡Œã„ã¾ã—ãŸã€‚

Objective-Cã€`objc_util`ã€ã‚µã‚¦ãƒ³ãƒ‰ãƒ‡ãƒ¼ã‚¿ã€Python ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã¨ã€ã•ã¾ã–ã¾ãªè¦ç´ ãŒå…¥ã‚Šæ··ã˜ã‚Šã€å¤§å¤‰ã§ã—ãŸã­ã€‚

ã“ã®ã‚³ãƒ¼ãƒ‰ã‚’ãƒ™ãƒ¼ã‚¹ã«è¶³ã—ãŸã‚Šå¼•ã„ãŸã‚Šã—ã¦ã€ã‚µã‚¦ãƒ³ãƒ‰ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°ã‚’æ¥½ã—ã‚“ã§ã„ãŸã ã‘ã¾ã™ã¨å¹¸ã„ã§ã™ã€‚

éå»ã«å®Ÿè£…ã—ãŸã€ä½ãƒ¬ã‚¤ãƒ¤ãƒ¼ã®éŸ³ã‚’å‡ºã™ãƒªãƒã‚¸ãƒˆãƒªã¯ã“ã¡ã‚‰ã§ã™ã€‚

[pome-ta/pysta-sine_wave001](https://github.com/pome-ta/pysta-sine_wave001)

https://github.com/pome-ta/pysta-sine_wave001

æ¬¡å›ã¯ã€SceneKit Frameworkï¼ˆPythonista3 ã®`scene` ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã§ã¯ãªã„ï¼‰ã«å…¥ã£ã¦ã„ãã¾ã™ã€‚

æ¥½ã—ã„ 3DCG ã®ä¸–ç•ŒãŒå¾…ã£ã¦ã¾ã™ã‚ˆãƒ¼ã€‚

ã“ã“ã¾ã§ã€èª­ã‚“ã§ã„ãŸã ãã‚ã‚ŠãŒã¨ã†ã”ã–ã„ã¾ã—ãŸã€‚

ğŸ‘‡ : 17 æ—¥ç›®

https://qiita.com/pome-ta/items/551bf5fb2448ddcacae0

## ã›ã‚“ã§ã‚“

### Discord

Pythonista3 ã®æ—¥æœ¬èªã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£ãƒ¼ãŒã‚ã‚Šã¾ã™ã€‚ã¿ãªã•ã‚“å„ªã—ãã¦ã€ã‚ã‹ã‚‰ãªã„ã¨ã“ã‚ã‚‚è¦ªèº«ã«æ•™ãˆã¦ãã‚Œã‚‹ã®ã§ã“ã®æ©Ÿä¼šã«è¦—ã„ã¦ã¿ã¦ãã ã•ã„ã€‚

https://t.co/0IOW2hn1VC

### æ›¸ç±

iPhone/iPad ã§ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°ã™ã‚‹æœ€å¼·ã®æœ¬ã€‚

- [Python ã‚„ Jupyter ã§ iPhone/iPad å…ˆç«¯æ©Ÿèƒ½ã‚’ç°¡å˜ï½¥è‡ªç”±ã«ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°ï¼ã€Œæ´»ç”¨ç¯‡ã€ï¼šhirax](https://techbookfest.org/product/1WiyV4LEev3f4YrzesRKWV?productVariantID=axX32srsSgtLtZWUtjkj99)

https://techbookfest.org/product/1WiyV4LEev3f4YrzesRKWV?productVariantID=axX32srsSgtLtZWUtjkj99

- [Python ã‚„ Jupyter ã§ iPhone/iPad å…ˆç«¯æ©Ÿèƒ½ã‚’ç°¡å˜ï½¥è‡ªç”±ã«ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°ï¼ã€ŒåœŸå°ç¯‡ã€ï¼šhirax](https://techbookfest.org/product/wTZTyeibm5GQ5XgdfMrEBV?productVariantID=kRDmN1udbEYZUWbETdwL8r)

https://techbookfest.org/product/wTZTyeibm5GQ5XgdfMrEBV?productVariantID=kRDmN1udbEYZUWbETdwL8r

### ãã®ä»–

- ã‚µãƒ³ãƒ—ãƒ«ã‚³ãƒ¼ãƒ‰

[Pythonista3 Advent Calendar 2022](https://qiita.com/advent-calendar/2022/pythonista3) ã§ã®ã‚³ãƒ¼ãƒ‰ã‚’ã¾ã¨ã‚ã¦ã„ã‚‹ãƒªãƒã‚¸ãƒˆãƒªãŒã‚ã‚Šã¾ã™ã€‚

ã‚³ãƒ¼ãƒ‰ã®ã‚¨ãƒ©ãƒ¼ã‚„å¤‰ãªã¨ã“ã‚ã‚„æ”¹å–„ç‚¹ãªã©ã€‚ã”æŒ‡æ‘˜ã‚„ PR ãŠå¾…ã¡ã—ã¦ãŠã‚Šã¾ã™ãƒ¼

https://github.com/pome-ta/Pythonista3AdventCalendar2022sampleCode

- Twitter

ãªã‚“ã—ã‹ã‚¬ãƒãƒ£ã‚¬ãƒãƒ£ã—ã¦ã„ã¾ã™ãŒã€ãŠæ°—å…¼ã­ãªããŠå£°ãŒã‘ãã ã•ã„ã¾ã›ãƒ¼

https://twitter.com/pome_ta93

<blockquote class="twitter-tweet"><p lang="ja" dir="ltr">ã‚„ã‚Œã‚‹ã‹ã€ã‚„ã‚Œãªã„ã‹ã€‚ã§ã¯ãªãã€ã‚„ã‚‹ã‚“ã ã‘ã©ã‚‚ã€ç´¹ä»‹èª¬æ˜ã™ã‚‹ã“ã¨ã¯å°½ããªã„ã¨æ€ã†ã‘ã©ã€ç· ã‚åˆ‡ã‚Šå®ˆã‚Œã‚‹ã‹ï¼Ÿã£ã¦è©±ã‚ˆï¼ï¼ˆã‚¯ã‚ºï¼‰<br><br>Pythonista3 Advent Calendar 2022 <a href="https://t.co/JKUxA525Pt">https://t.co/JKUxA525Pt</a> <a href="https://twitter.com/hashtag/Qiita?src=hash&amp;ref_src=twsrc%5Etfw">#Qiita</a></p>&mdash; pome-ta (@pome_ta93) <a href="https://twitter.com/pome_ta93/status/1588570697777152006?ref_src=twsrc%5Etfw">November 4, 2022</a></blockquote> <script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>

- GitHub

åŸºæœ¬çš„ã« GitHub ã«ã‚³ãƒ¼ãƒ‰ã‚’ã‚ã’ã¦ã„ã‚‹ã®ã§ã€ä½•ã«ãƒãƒã£ã¦ä½•ã‚’å®Ÿè£…ã—ã¦ã„ã‚‹ã®ã‹è¦³æ¸¬ã§ãã‚‹ã¨æ€ã„ã¾ã™ã€‚

https://github.com/pome-ta
