---
title: Pythonista3 ã¨æ©Ÿæ¢°å­¦ç¿’ï¼ˆCore MLï¼‰ ã®Vision Framework ã§ã€æ‰‹ã‚’è¿½ã£ã‹ã‘ã¦ã‚‚ã‚‰ã†
tags:
  - Python
  - æ©Ÿæ¢°å­¦ç¿’
  - Pythonista3
  - coreML
  - VisionFramework
private: false
updated_at: '2022-12-23T07:01:01+09:00'
id: bcac9d3209caa60f70b6
organization_url_name: null
slide: false
ignorePublish: false
---

ã“ã®è¨˜äº‹ã¯ã€[Pythonista3 Advent Calendar 2022](https://qiita.com/advent-calendar/2022/pythonista3) ã® 23 æ—¥ç›®ã®è¨˜äº‹ã§ã™ã€‚

ğŸ‘‡ : 22 æ—¥ç›®

https://qiita.com/pome-ta/items/84729804cce04f870fd6

ğŸ‘‡ : 24 æ—¥ç›®

https://qiita.com/pome-ta/items/52053dd6c9e39da6a29a

https://qiita.com/advent-calendar/2022/pythonista3

ä¸€æ–¹çš„ãªåã£ãŸç›®ç·šã§ã€Pythonista3 ã‚’ç´¹ä»‹ã—ã¦ã„ãã¾ã™ã€‚

ã»ã¼æ¯æ—¥ iPhoneï¼ˆPythonista3ï¼‰ã§ã€ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã‚’ã—ã¦ã„ã‚‹è€…ã§ã™ã€‚ã‚ˆã‚ã—ããŠé¡˜ã„ã—ã¾ã™ã€‚

ä»¥ä¸‹ã€ç§ã® 2022 å¹´ 12 æœˆæ™‚ç‚¹ã®ç’°å¢ƒã§ã™ã€‚

```sysInfo.log
--- SYSTEM INFORMATION ---
* Pythonista 3.3 (330025), Default interpreter 3.6.1
* iOS 16.1.1, model iPhone12,1, resolution (portrait) 828.0 x 1792.0 @ 2.0
```

ä»–ã®ç’°å¢ƒ(iPad ã‚„ç«¯æœ«ã®ç¨®é¡ã€iOS ã®ãƒãƒ¼ã‚¸ãƒ§ãƒ³é•ã„)ã§ã¯ã€æ„å›³ã¨ã—ãªã„æŒ™å‹•(ã‚¨ãƒ©ãƒ¼ã«ãªã‚‹)ãªã‚‹å ´åˆã‚‚ã‚ã‚Šã¾ã™ã€‚ã”äº†æ‰¿ãã ã•ã„ã€‚

ã¡ãªã¿ã«ã€`model iPhone12,1` ã¯ã€iPhone11 ã§ã™ã€‚

## ã“ã®è¨˜äº‹ã§ã‚ã‹ã‚‹ã“ã¨

- ã‚«ãƒ¡ãƒ©ã®ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ãªæƒ…å ±ã‚’ Pythonista3 ã® View ã«è¡¨ç¤ºã•ã›ã‚‹
- Vision Framework ã‚’ä½¿ã„ã€æ‰‹ã®æƒ…å ±ã‚’æ¤œå‡º
- æ‰‹ã®ãƒ‘ãƒ¼ãƒ„ã‚’ Tracking ã™ã‚‹

## æ©Ÿæ¢°å­¦ç¿’ã‚‚ã™ã”ã„ã—ã€iPhone ã‚‚ã™ã”ã„

å‰å›ã¯ã€é™æ­¢ç”»ã‚’æ©Ÿæ¢°å­¦ç¿’ã§é¡”ã®æ¤œå‡ºã‚’ã—ã¾ã—ãŸã€‚

äº‹å‰ã«ç”¨æ„ã•ã‚Œã¦ã„ã‚‹ã€Core ML ãƒ¢ãƒ‡ãƒ«ã€‚æ¯”è¼ƒçš„å®¹æ˜“ã«å®Ÿè£…ã§ãã‚‹ Vision Frameworkã€‚ãã—ã¦ä¸€ç¬ã§å‡¦ç†ã—ã¦ãã‚Œã‚‹ iPhone ã¡ã‚ƒã‚“ã€‚

ã©ã‚Œã‚‚ã™ã”ã„ã€‚

ã‹ãŒãã®ã¡ã‹ã‚‰ã£ã¦ã™ã’ãƒ¼ï¼

## æ©Ÿæ¢°å­¦ç¿’ã¨ã‹è¨€ã†å‰ã«ã€View ã«ã‚«ãƒ¡ãƒ©æƒ…å ±ã‚’å‡ºã™

ä»Šå›ã®ä¸­ã§ã€ä¸€ç•ªã“ã“ãŒé¢å€’ã‹ã‚‚ã—ã‚Œã¾ã›ã‚“ã€‚View ã®å†…ã§ã‚«ãƒ¡ãƒ©ã‹ã‚‰å¾—ãŸæƒ…å ±ã‚’ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã«å‡ºã—ã¾ã™ã€‚

ARKit ã§ã¯ã€SceneKit ã® SCNView ã®ã‚µãƒ–ã‚¯ãƒ©ã‚¹ã¨ã—ã¦ã® ARSCNView ãŒã„ã„æ„Ÿã˜ã«ã‚„ã£ã¦ãã‚Œã¾ã—ãŸã€‚

[ARSCNView | Apple Developer Documentation](https://developer.apple.com/documentation/arkit/arscnview?language=objc)

https://developer.apple.com/documentation/arkit/arscnview?language=objc

Vision ã«ã¯ç”¨æ„ãŒãªã„ã®ã§è‡ªåˆ†ã§çµ„ã‚€ã“ã¨ã«ãªã‚Šã¾ã™ã€‚

### æœ€ä½é™ã«ãŸã ã‚«ãƒ¡ãƒ©ã®æƒ…å ±ã‚’å‚ã‚Œæµã™ã ã‘

```py
from objc_util import ObjCClass
import ui

import pdbg

AVCaptureVideoPreviewLayer = ObjCClass('AVCaptureVideoPreviewLayer')
AVCaptureSession = ObjCClass('AVCaptureSession')
AVCaptureDevice = ObjCClass('AVCaptureDevice')
AVCaptureDeviceInput = ObjCClass('AVCaptureDeviceInput')
AVCaptureVideoDataOutput = ObjCClass('AVCaptureVideoDataOutput')


class CameraView(ui.View):
 def __init__(self, *args, **kwargs):
   ui.View.__init__(self, *args, **kwargs)
   self.bg_color = 'green'
   self.flex = 'WH'
   self.layer = self.objc_instance.layer()

   self.previewLayer: AVCaptureVideoPreviewLayer
   self.init()

 def layout(self):
   self.previewLayer.frame = self.objc_instance.bounds()

 def init(self):
   previewLayer = AVCaptureVideoPreviewLayer.new()
   self.layer.addSublayer_(previewLayer)
   self.previewLayer = previewLayer


class CameraViewController:
 def __init__(self):
   self.cameraView = CameraView()

   self.cameraFeedSession: AVCaptureSession
   self.viewDidLoad()
   self.viewDidAppear()

 def viewDidLoad(self):
   pass

 def viewDidAppear(self):
   _resizeAspectFill = 'AVLayerVideoGravityResizeAspectFill'

   self.cameraView.previewLayer.videoGravity = _resizeAspectFill
   self.setupAVSession()
   self.cameraView.previewLayer.session = self.cameraFeedSession

   self.cameraFeedSession.startRunning()

 def viewWillDisappear(self):
   self.cameraFeedSession.stopRunning()

 def setupAVSession(self):
   _builtInWideAngleCamera = 'AVCaptureDeviceTypeBuiltInWideAngleCamera'
   _video = 'vide'
   _front = 2
   _back = 1

   videoDevice = AVCaptureDevice.defaultDeviceWithDeviceType_mediaType_position_(
     _builtInWideAngleCamera, _video, _back)

   deviceInput = AVCaptureDeviceInput.deviceInputWithDevice_error_(
     videoDevice, None)

   session = AVCaptureSession.new()
   session.beginConfiguration()
   _Preset_high = 'AVCaptureSessionPresetHigh'
   session.setSessionPreset_(_Preset_high)

   if session.canAddInput_(deviceInput):
     session.addInput_(deviceInput)
   else:
     raise

   dataOutput = AVCaptureVideoDataOutput.new()
   if session.canAddOutput_(dataOutput):
     session.addOutput_(dataOutput)
     dataOutput.alwaysDiscardsLateVideoFrames = True
   else:
     raise
   session.commitConfiguration()
   self.cameraFeedSession = session


class View(ui.View):
 def __init__(self, *args, **kwargs):
   ui.View.__init__(self, *args, **kwargs)
   self.bg_color = 'maroon'
   self.cvc = CameraViewController()
   self.add_subview(self.cvc.cameraView)

 def will_close(self):
   self.cvc.viewWillDisappear()


if __name__ == '__main__':
 view = View()
 view.present(style='fullscreen', orientations=['portrait'])

```

éŒ²ç”»ã®ã§ããªã„ã€ãŸã ãŸã ãƒ“ãƒ‡ã‚ªãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ãªçŠ¶æ…‹ã§ã™ã€‚

`AVCapture ã€œ` ã®ã‚¯ãƒ©ã‚¹ã«ã‚ˆã‚Š

- ã©ã®ã‚«ãƒ¡ãƒ©ã‚’å–å¾—ã™ã‚‹ã‹
  - [AVCaptureDevice | Apple Developer Documentation](https://developer.apple.com/documentation/avfoundation/avcapturedevice?language=objc)
- ã‚«ãƒ¡ãƒ©ã‚’èµ·å‹•ã•ã›ã‚‹
  - [AVCaptureSession | Apple Developer Documentation](https://developer.apple.com/documentation/avfoundation/avcapturesession?language=objc)
- ã‚«ãƒ¡ãƒ©æƒ…å ±ã®å…¥å‡ºåŠ›
  - [AVCaptureDeviceInput | Apple Developer Documentation](https://developer.apple.com/documentation/avfoundation/avcapturedeviceinput?language=objc)
  - [AVCaptureVideoDataOutput | Apple Developer Documentation](https://developer.apple.com/documentation/avfoundation/avcapturevideodataoutput?language=objc)
- View ã® Layler ã«æç”»
  - [AVCaptureVideoPreviewLayer | Apple Developer Documentation](https://developer.apple.com/documentation/avfoundation/avcapturevideopreviewlayer?language=objc)

ã“ã®è¨­å®šã‚’ã™ã‚‹ã“ã¨ã§ã€ã‚„ã£ã¨ã‚«ãƒ¡ãƒ©ã‹ã‚‰ã®æƒ…å ±ã‚’ View ã«å‡ºã™ã“ã¨ãŒã§ãã¾ã™ã€‚

### Delegate ã‚’è¨­å®šã—ã€ã‚«ãƒ¡ãƒ©ã®æƒ…å ±ã‚’å–å¾—æ“ä½œã§ãã‚‹ã‚ˆã†ã«ã™ã‚‹

```py
def create_sampleBufferDelegate(self):
  # --- /delegate
  def captureOutput_didOutputSampleBuffer_fromConnection_(
      _self, _cmd, _output, _sampleBuffer, _connection):

    sampleBuffer = ObjCInstance(_sampleBuffer)
    print('o')

  def captureOutput_didDropSampleBuffer_fromConnection_(
      _felf, _cmd, _output, _sampleBuffer, _connection):
    ObjCInstance(_sampleBuffer)  # todo: å‘¼ã¶ã ã‘
    print('d')

    # --- delegate/

  _methods = [
    captureOutput_didOutputSampleBuffer_fromConnection_,
    captureOutput_didDropSampleBuffer_fromConnection_,
  ]

  _protocols = ['AVCaptureVideoDataOutputSampleBufferDelegate']

  sampleBufferDelegate = create_objc_class(
    'sampleBufferDelegate', methods=_methods, protocols=_protocols)
  return sampleBufferDelegate.new()
```

`CameraViewController` class å†…ã«`create_objc_class` ã‚ˆã‚Š`delegate` ã‚’å®Ÿè£…ã—ã¦ã„ãã¾ã™ã€‚

ï¼ˆé›°å›²æ°—ç†è§£ã§ã™ãŒï¼‰`dispatch queue` ãŒ Delegate å®£è¨€æ™‚ã«å¿…è¦ã¿ãŸã„ãªã®ã§ã€é–¢æ•°ã¨ã—ã¦æº–å‚™ã—ã¦ãŠãã¾ã™ã€‚

[Dispatch Queue | Apple Developer Documentation](https://developer.apple.com/documentation/dispatch/dispatch_queue)

https://developer.apple.com/documentation/dispatch/dispatch_queue

`dispatch_queue_create` ãŒ Function ãªã®ã§ã€`objc_util.c` ã§ã€å‘¼ã³å‡ºã—ã¦ã‹ã‚‰é–¢æ•°å®£è¨€ã‚’ã—ã¦ã„ã¾ã™ã€‚

```py
from objc_util import c

def dispatch_queue_create(_name, parent):
  _func = c.dispatch_queue_create
  _func.argtypes = [ctypes.c_char_p, ctypes.c_void_p]
  _func.restype = ctypes.c_void_p
  name = _name.encode('ascii')
  return ObjCInstance(_func(name, parent))
```

[dispatch_queue_create | Apple Developer Documentation](https://developer.apple.com/documentation/dispatch/1453030-dispatch_queue_create)

https://developer.apple.com/documentation/dispatch/1453030-dispatch_queue_create

`delegate` ã¨`Dispatch Queue` ã‚’è¨­å®šã—ã€å®Ÿè£…åæ˜ ã•ã›ãŸã‚³ãƒ¼ãƒ‰ãŒä»¥ä¸‹ã«ãªã‚Šã¾ã™:

```py
import ctypes

from objc_util import c, ObjCClass, ObjCInstance, create_objc_class
from objc_util import UIBezierPath
import ui

import pdbg

AVCaptureVideoPreviewLayer = ObjCClass('AVCaptureVideoPreviewLayer')
AVCaptureSession = ObjCClass('AVCaptureSession')
AVCaptureDevice = ObjCClass('AVCaptureDevice')
AVCaptureDeviceInput = ObjCClass('AVCaptureDeviceInput')
AVCaptureVideoDataOutput = ObjCClass('AVCaptureVideoDataOutput')

CAShapeLayer = ObjCClass('CAShapeLayer')


def dispatch_queue_create(_name, parent):
  _func = c.dispatch_queue_create
  _func.argtypes = [ctypes.c_char_p, ctypes.c_void_p]
  _func.restype = ctypes.c_void_p
  name = _name.encode('ascii')
  return ObjCInstance(_func(name, parent))


class CameraView(ui.View):
  def __init__(self, *args, **kwargs):
    ui.View.__init__(self, *args, **kwargs)
    self.bg_color = 'green'
    self.flex = 'WH'
    self.layer = self.objc_instance.layer()

    self.previewLayer: AVCaptureVideoPreviewLayer
    self.overlayLayer: CAShapeLayer
    self.init()

  def layout(self):
    self.previewLayer.frame = self.objc_instance.bounds()
    self.overlayLayer.frame = self.objc_instance.bounds()

  def init(self):
    previewLayer = AVCaptureVideoPreviewLayer.new()
    overlayLayer = CAShapeLayer.new()

    self.previewLayer = previewLayer
    self.overlayLayer = overlayLayer
    self.layer.addSublayer_(self.previewLayer)
    self.setupOverlay()

  def setupOverlay(self):
    self.previewLayer.addSublayer_(self.overlayLayer)


class CameraViewController:
  def __init__(self):
    self.cameraView = CameraView()
    self.videoDataOutputQueue = dispatch_queue_create('imageDispatch', None)
    self.delegate = self.create_sampleBufferDelegate()

    self.cameraFeedSession: AVCaptureSession
    self.viewDidLoad()
    self.viewDidAppear()

  def viewDidLoad(self):
    pass

  def viewDidAppear(self):
    _resizeAspectFill = 'AVLayerVideoGravityResizeAspectFill'

    self.cameraView.previewLayer.videoGravity = _resizeAspectFill
    self.setupAVSession()
    self.cameraView.previewLayer.session = self.cameraFeedSession

    self.cameraFeedSession.startRunning()

  def viewWillDisappear(self):
    self.cameraFeedSession.stopRunning()

  def setupAVSession(self):
    _builtInWideAngleCamera = 'AVCaptureDeviceTypeBuiltInWideAngleCamera'
    _video = 'vide'
    _front = 2
    _back = 1

    videoDevice = AVCaptureDevice.defaultDeviceWithDeviceType_mediaType_position_(
      _builtInWideAngleCamera, _video, _back)

    deviceInput = AVCaptureDeviceInput.deviceInputWithDevice_error_(
      videoDevice, None)

    session = AVCaptureSession.new()
    session.beginConfiguration()
    _Preset_high = 'AVCaptureSessionPresetHigh'
    session.setSessionPreset_(_Preset_high)

    if session.canAddInput_(deviceInput):
      session.addInput_(deviceInput)
    else:
      raise

    dataOutput = AVCaptureVideoDataOutput.new()
    if session.canAddOutput_(dataOutput):
      session.addOutput_(dataOutput)
      dataOutput.alwaysDiscardsLateVideoFrames = True
      dataOutput.setSampleBufferDelegate_queue_(self.delegate,
                                                self.videoDataOutputQueue)
    else:
      raise
    session.commitConfiguration()
    self.cameraFeedSession = session

  def create_sampleBufferDelegate(self):
    # --- /delegate
    def captureOutput_didOutputSampleBuffer_fromConnection_(
        _self, _cmd, _output, _sampleBuffer, _connection):

      sampleBuffer = ObjCInstance(_sampleBuffer)
      print('didOutputSampleBuffer')

    def captureOutput_didDropSampleBuffer_fromConnection_(
        _felf, _cmd, _output, _sampleBuffer, _connection):
      ObjCInstance(_sampleBuffer)  # todo: å‘¼ã¶ã ã‘
      print('didDropSampleBuffer')

      # --- delegate/

    _methods = [
      captureOutput_didOutputSampleBuffer_fromConnection_,
      captureOutput_didDropSampleBuffer_fromConnection_,
    ]

    _protocols = ['AVCaptureVideoDataOutputSampleBufferDelegate']

    sampleBufferDelegate = create_objc_class(
      'sampleBufferDelegate', methods=_methods, protocols=_protocols)
    return sampleBufferDelegate.new()


class View(ui.View):
  def __init__(self, *args, **kwargs):
    ui.View.__init__(self, *args, **kwargs)
    self.bg_color = 'maroon'
    self.cvc = CameraViewController()
    self.add_subview(self.cvc.cameraView)

  def will_close(self):
    self.cvc.viewWillDisappear()


if __name__ == '__main__':
  view = View()
  view.present(style='fullscreen', orientations=['portrait'])

```

#### æ°¸ç¶šçš„ã«`delegate` ã‚’å‘¼ã³å‡ºã™

`captureOutput_didOutputSampleBuffer_fromConnection_` ã¨ã€`captureOutput_didDropSampleBuffer_fromConnection_` ã® 2 ã¤ã‚’ãƒ¡ã‚½ãƒƒãƒ‰ã¨ã—ã¦ã€æŒ‡å®šã—ã¦ã„ã¾ã™ã€‚

`Output` ã®å‘¼ã³å‡ºã—ã®ã¿ã§å•é¡Œãªã•ãã†ã§ã™ãŒã€`Output` ã®ã¿ã§ã™ã¨ã€æœ€åˆã®ãƒ•ãƒ¬ãƒ¼ãƒ ï¼ˆï¼Ÿï¼‰ã®`5,60` ãã‚‰ã„ã—ã‹ã‚³ãƒ¼ãƒ«ã—ã¦ãã‚Œã¾ã›ã‚“ã€‚

`Drop` ã‚‚ã‚³ãƒ¼ãƒ«ï¼ˆã»ã¼ç©ºæ‰“ã¡ï¼‰ã•ã›ã‚‹ã“ã¨ã§ã€`Output` -> `Drop` -> `Output` -> `Drop` -> `...` ã¨ã€é †ç•ªã«æ°¸ç¶šã—ã¦ã‚³ãƒ¼ãƒ«ã—ã¦ãã‚Œã‚‹ã‚ˆã†ã«ãªã‚Šã¾ã™ã€‚

ã“ã“ã‚‰ã¸ã‚“ã®ã€ç†ç”±ã¯ã‚ˆãã‚ã‹ã£ã¦ã„ã¾ã›ã‚“ ğŸ˜‡

### ã‚«ãƒ¡ãƒ©å´ã®æº–å‚™ãŒæ•´ã†

`CameraView` class ã«ã¦`ui.View` ã‚’ç¶™æ‰¿ã•ã‚‹ã“ã¨ã§

- `objc_util`ï¼ˆ`ui.View.objc_instance`ï¼‰å´
  - ã‚«ãƒ¡ãƒ©ã‚’æç”»ã•ã›ã‚‹ Layler ç­‰ã®æ“ä½œ
- Pythonï¼ˆPythonista3ï¼‰å´
  - `.flex` ã§å…¨ç”»é¢

ã¨ã€æŸ”è»Ÿã«ã‚„ã‚Šã¨ã‚ŠãŒã§ãã‚‹ã‚ˆã†ã«ã—ã¦ã„ã¾ã™ã€‚

ä»Šå¾Œæ¤œçŸ¥ã—ãŸæƒ…å ±ã‚’å¯è¦–åŒ–ã™ã‚‹ãŸã‚ã® Layler ã‚‚æŒãŸã›ã¾ã™ã€‚

`CameraViewController` class ã§ã¯ã€`delegate` ã«ã‚ˆã‚Šã‚«ãƒ¡ãƒ©ã‹ã‚‰ã®ï¼ˆæ¯å›ã®ã‚«ãƒ¡ãƒ©ä¸Šã®ã‚­ãƒ£ãƒ—ãƒãƒ£ãƒãƒƒãƒ•ã‚¡ãƒ¼ï¼‰æƒ…å ±ã‚’å¾—ã‚‹ã“ã¨ãŒã§ãã¾ã—ãŸã€‚

ã“ã‚Œã§ã‚„ã£ã¨ã€Vision Framework ã¸æƒ…å ±ã‚’æŠ•ã’ã¤ã‘ã¦ã€æ©Ÿæ¢°å­¦ç¿’çµæœã‚’è¿”ã—ã¦ã‚‚ã‚‰ã†æµã‚ŒãŒã§ãã¾ã—ãŸã€‚

## `VNDetectHumanHandPoseRequest` ã§æ‰‹ã® Tracking âœ‹

æ¤œçŸ¥ã—ãŸäººå·®ã—æŒ‡ã®å…ˆã‚’ Tracking ã—ã¤ã¤ã€ãã®ä»–ã®æ‰‹ã®æƒ…å ±ã‚’ View ä¸Šã«ãƒ†ã‚­ã‚¹ãƒˆã¨ã—ã¦å‡ºåŠ›ã—ã¦ã„ã¾ã™ã€‚

```py
from math import pi
import ctypes

from objc_util import c, ObjCClass, ObjCInstance, create_objc_class, on_main_thread
from objc_util import UIBezierPath, UIColor, CGRect
import ui

import pdbg

VNDetectHumanHandPoseRequest = ObjCClass('VNDetectHumanHandPoseRequest')
VNSequenceRequestHandler = ObjCClass('VNSequenceRequestHandler')

AVCaptureVideoPreviewLayer = ObjCClass('AVCaptureVideoPreviewLayer')
AVCaptureSession = ObjCClass('AVCaptureSession')
AVCaptureDevice = ObjCClass('AVCaptureDevice')
AVCaptureDeviceInput = ObjCClass('AVCaptureDeviceInput')
AVCaptureVideoDataOutput = ObjCClass('AVCaptureVideoDataOutput')

CAShapeLayer = ObjCClass('CAShapeLayer')


def dispatch_queue_create(_name, parent):
  _func = c.dispatch_queue_create
  _func.argtypes = [ctypes.c_char_p, ctypes.c_void_p]
  _func.restype = ctypes.c_void_p
  name = _name.encode('ascii')
  return ObjCInstance(_func(name, parent))


def parseCGRect(cg_rect: CGRect) -> tuple:
  origin, size = [cg_rect.origin, cg_rect.size]
  return (origin.x, origin.y, size.width, size.height)


class CameraView(ui.View):
  def __init__(self, *args, **kwargs):
    ui.View.__init__(self, *args, **kwargs)
    self.bg_color = 'green'
    self.flex = 'WH'
    self.log_area = ui.TextView()
    self.log_area.editable = False
    self.log_area.flex = 'WH'
    self.log_area.font = ('Inconsolata', 10)
    self.log_area.bg_color = (0.0, 0.0, 0.0, 0.0)
    self.layer = self.objc_instance.layer()

    self.previewLayer: AVCaptureVideoPreviewLayer
    self.overlayLayer: CAShapeLayer
    self.init()

    self.log_area.text = ''
    # layer ã‚’é‡ã­ãŸå¾Œã§ãªã„ã¨ã€éš ã‚Œã¦ã—ã¾ã†
    self.add_subview(self.log_area)

  def layout(self):
    self.previewLayer.frame = self.objc_instance.bounds()
    self.overlayLayer.frame = self.objc_instance.bounds()

  def update_log_area(self, text):
    self.log_area.text = f'{text}'

  def init(self):
    previewLayer = AVCaptureVideoPreviewLayer.new()
    overlayLayer = CAShapeLayer.new()

    self.layer.addSublayer_(previewLayer)
    self.previewLayer = previewLayer
    self.overlayLayer = overlayLayer
    self.setupOverlay()

  def setupOverlay(self):
    self.previewLayer.addSublayer_(self.overlayLayer)
    self.setCAShapeLayer()

  def setCAShapeLayer(self):
    _blueColor = UIColor.blueColor().cgColor()
    _cyanColor = UIColor.cyanColor().cgColor()

    self.overlayLayer.setLineWidth_(2.0)
    self.overlayLayer.setStrokeColor_(_blueColor)
    self.overlayLayer.setFillColor_(_cyanColor)
    self.previewLayer.addSublayer_(self.overlayLayer)

  @on_main_thread
  def showPoints(self, _x, _y):
    _, _, _width, _height = parseCGRect(self.overlayLayer.frame())
    x = _width - (_width * (1 - _x))
    y = _height - (_height * _y)

    radius = 8.0
    startAngle = 0.0
    endAngle = pi * 2.0

    arc = UIBezierPath.new()
    arc.addArcWithCenter_radius_startAngle_endAngle_clockwise_(
      (x, y), radius, startAngle, endAngle, True)

    self.overlayLayer.setPath_(arc.CGPath())


class CameraViewController:
  def __init__(self):
    self.cameraView = CameraView()
    _name = 'CameraFeedDataOutput'
    self.videoDataOutputQueue = dispatch_queue_create(_name, None)
    self.delegate = self.create_sampleBufferDelegate()

    self.cameraFeedSession: AVCaptureSession
    self.handPoseRequest: VNDetectHumanHandPoseRequest
    self.viewDidLoad()
    self.viewDidAppear()

  def viewDidLoad(self):
    handPoseRequest = VNDetectHumanHandPoseRequest.new()
    handPoseRequest.maximumHandCount = 1

    self.handPoseRequest = handPoseRequest

  def viewDidAppear(self):
    _resizeAspectFill = 'AVLayerVideoGravityResizeAspectFill'

    self.cameraView.previewLayer.videoGravity = _resizeAspectFill
    self.setupAVSession()
    self.cameraView.previewLayer.session = self.cameraFeedSession

    self.cameraFeedSession.startRunning()

  def viewWillDisappear(self):
    self.cameraFeedSession.stopRunning()

  def setupAVSession(self):
    _builtInWideAngleCamera = 'AVCaptureDeviceTypeBuiltInWideAngleCamera'
    _video = 'vide'
    _front = 2
    _back = 1

    videoDevice = AVCaptureDevice.defaultDeviceWithDeviceType_mediaType_position_(
      _builtInWideAngleCamera, _video, _back)

    deviceInput = AVCaptureDeviceInput.deviceInputWithDevice_error_(
      videoDevice, None)

    session = AVCaptureSession.new()
    session.beginConfiguration()
    _Preset_high = 'AVCaptureSessionPresetHigh'
    session.setSessionPreset_(_Preset_high)

    if session.canAddInput_(deviceInput):
      session.addInput_(deviceInput)
    else:
      raise

    dataOutput = AVCaptureVideoDataOutput.new()
    if session.canAddOutput_(dataOutput):
      session.addOutput_(dataOutput)
      dataOutput.alwaysDiscardsLateVideoFrames = True
      dataOutput.setSampleBufferDelegate_queue_(self.delegate,
                                                self.videoDataOutputQueue)
    else:
      raise
    session.commitConfiguration()
    self.cameraFeedSession = session

  def detectedHandPose_request(self, request_list):
    _all = 'VNIPOAll'  # VNHumanHandPoseObservationJointsGroupNameAll
    _point = 'VNHLKITIP'  # äººå·®ã—æŒ‡å…ˆç«¯
    for result in request_list:
      handParts = result.recognizedPointsForJointsGroupName_error_(_all, None)

      self.cameraView.update_log_area(f'{handParts}')

      recognizedPoint = handParts[_point]
      x_point = recognizedPoint.x()
      y_point = recognizedPoint.y()
      self.cameraView.showPoints(x_point, y_point)

  def create_sampleBufferDelegate(self):
    sequenceHandler = VNSequenceRequestHandler.new()
    _right = 6  # kCGImagePropertyOrientationRight

    # --- /delegate
    def captureOutput_didOutputSampleBuffer_fromConnection_(
        _self, _cmd, _output, _sampleBuffer, _connection):
      sampleBuffer = ObjCInstance(_sampleBuffer)
      sequenceHandler.performRequests_onCMSampleBuffer_orientation_error_(
        [self.handPoseRequest], sampleBuffer, _right, None)

      observation_array = self.handPoseRequest.results()
      if observation_array:
        self.detectedHandPose_request(observation_array)

    def captureOutput_didDropSampleBuffer_fromConnection_(
        _felf, _cmd, _output, _sampleBuffer, _connection):
      ObjCInstance(_sampleBuffer)  # todo: å‘¼ã¶ã ã‘

    # --- delegate/

    _methods = [
      captureOutput_didOutputSampleBuffer_fromConnection_,
      captureOutput_didDropSampleBuffer_fromConnection_,
    ]

    _protocols = ['AVCaptureVideoDataOutputSampleBufferDelegate']

    sampleBufferDelegate = create_objc_class(
      'sampleBufferDelegate', methods=_methods, protocols=_protocols)
    return sampleBufferDelegate.new()


class View(ui.View):
  def __init__(self, *args, **kwargs):
    ui.View.__init__(self, *args, **kwargs)
    self.bg_color = 'maroon'
    self.cvc = CameraViewController()
    self.add_subview(self.cvc.cameraView)

  def will_close(self):
    self.cvc.viewWillDisappear()


if __name__ == '__main__':
  view = View()
  view.present(style='fullscreen', orientations=['portrait'])

```

å‰å›å®Ÿè£…ã—ãŸã€é™æ­¢ç”»æ¤œå‡ºã®å¿œç”¨ã¨ãªã‚Šã¾ã™ã€‚

ã‚«ãƒ¡ãƒ©ã‚’ View ã«å‡ºã™ã‚ˆã‚Šã‚‚ã€ã‚³ãƒ¼ãƒ‰é‡å°‘ãªãï¼ˆæ¯”è¼ƒçš„æ¥½ã«ï¼‰å®Ÿè£…ã§ãã¾ã™ã€‚

### å‹•ç”»ã§ã® Request

`VNDetectHumanHandPoseRequest` ã¨ã€`VNSequenceRequestHandler` ã‚’ä½¿ã„ã¾ã™ã€‚

å‰å›ã®ã€Œé¡”æ¤œå‡ºã€ã«ç¶šãã€ã€Œæ‰‹æ¤œå‡ºã€ã‚‚äº‹å‰ã« class ã¨ã—ã¦ç”¨æ„ã•ã‚Œã¦ã„ã‚‹ã®ã¯ã„ã„ã§ã™ã­ã€‚

[VNDetectHumanHandPoseRequest | Apple Developer Documentation](https://developer.apple.com/documentation/vision/vndetecthumanhandposerequest?language=objc)

https://developer.apple.com/documentation/vision/vndetecthumanhandposerequest?language=objc

[VNSequenceRequestHandler | Apple Developer Documentation](https://developer.apple.com/documentation/vision/vnsequencerequesthandler?language=objc)

https://developer.apple.com/documentation/vision/vnsequencerequesthandler?language=objc

`VNImageRequestHandler` ã§ã¯ã†ã¾ãã„ã‹ãšã€`VNSequenceRequestHandler` ã‚’ Handler ã¨ã—ã¦ä½¿ã£ã¦ã„ã¾ã™ã€‚

ï¼ˆ`dispatch_queue` ç­‰ã® thread å‡¦ç†ãŒã†ã¾ãã„ã£ã¦ã„ãªã„ã®ã‹ã‚‚ã—ã‚Œã¾ã›ã‚“ï¼‰

[VNImageRequestHandler | Apple Developer Documentation](https://developer.apple.com/documentation/vision/vnimagerequesthandler?language=objc)

https://developer.apple.com/documentation/vision/vnimagerequesthandler?language=objc

æ¤œå‡ºã§ãã‚‹æ‰‹ã¯ä¸€ã¤ã§å•é¡Œãªã„ã®ã§ã€æœ€å¤§æ•°ã‚’`1` ã«:

```py
handPoseRequest = VNDetectHumanHandPoseRequest.new()
handPoseRequest.maximumHandCount = 1
```

`delegate` ã‚’ç”Ÿæˆã™ã‚‹ãƒ¡ã‚½ãƒƒãƒ‰å†…ã§ã€`VNSequenceRequestHandler` ã‚’å‘¼ã³å‡ºã—ã¾ã™ã€‚

å®Ÿéš›ã«`delegate` ã¨ã—ã¦èµ°ã‚‹ãƒ¡ã‚½ãƒƒãƒ‰å†…ã§ Request å‡¦ç†ã‚’æ¯å›ã•ã›ã¾ã™:

```py
def create_sampleBufferDelegate(self):
  sequenceHandler = VNSequenceRequestHandler.new()
  _right = 6  # kCGImagePropertyOrientationRight

  # --- /delegate
  def captureOutput_didOutputSampleBuffer_fromConnection_(
      _self, _cmd, _output, _sampleBuffer, _connection):
    sampleBuffer = ObjCInstance(_sampleBuffer)
    sequenceHandler.performRequests_onCMSampleBuffer_orientation_error_(
      [self.handPoseRequest], sampleBuffer, _right, None)

    observation_array = self.handPoseRequest.results()
    if observation_array:
      self.detectedHandPose_request(observation_array)
```

æ‰‹ãŒæ¤œå‡ºã•ã‚Œã‚‹ã¨ã€`observation_array` ã¸æƒ…å ±ãŒæ ¼ç´ã•ã‚Œã¾ã™ã€‚

å–å¾—ã§ããŸã‚‰ã€View ä¸Šã§ã‚ˆãã‚ˆã†ã«å‡¦ç†ã‚’ã—ã¦ã‚‚ã‚‰ã†ã‚ˆã†ã«`detectedHandPose_request` ãƒ¡ã‚½ãƒƒãƒ‰ã¸æŠ•ã’ã¾ã™ã€‚

Vision Framework ã®æ¤œå‡ºå‡¦ç†è‡ªä½“ã¯ã€ãƒ›ãƒ³ãƒˆé™æ­¢ç”»ã®æ™‚ã¨å¤‰ã‚ã‚‰ãªã„ã§ã™ã­ï¼ˆãŸã ã—ã€é«˜é€Ÿã§å‡¦ç†ã‚’ã—ã¦ãã‚Œã¦ã„ã‚‹ï¼‰ã€‚

#### `VNHumanHandPoseObservation` ã¨ã€`VNRecognizedPoint`

æ¤œå‡ºã—ãŸæ‰‹ã®æƒ…å ±ã®é…åˆ—ï¼ˆä»Šå›`maximumHandCount = 1` ãªã®ã§ 1 ã¤ï¼‰ã®ä¸­ã«ã€æ‰‹ã®å„ãƒ‘ãƒ¼ãƒ„ã§ã®æƒ…å ±ãŒå…¥ã£ã¦ã„ã¾ã™:

```py
observation_array = self.handPoseRequest.results()
```

æ‰‹ã®æƒ…å ±ã¯ã€`VNHumanHandPoseObservation` ã¨ã—ã¦è¿”ã•ã‚Œã¾ã™ã€‚

[VNHumanHandPoseObservation | Apple Developer Documentation](https://developer.apple.com/documentation/vision/vnhumanhandposeobservation?language=objc)

https://developer.apple.com/documentation/vision/vnhumanhandposeobservation?language=objc

##### å…¨éƒ¨å‘¼ã³å‡ºã™

`VNHumanHandPoseObservation` ã‹ã‚‰ã€å€‹ã€…ã®æƒ…å ±ãŒæ¬²ã—ã„ã®ã§:

```py
_all = 'VNIPOAll'  # VNHumanHandPoseObservationJointsGroupNameAll

handParts = result.recognizedPointsForJointsGroupName_error_(_all, None)
```

`VNHumanHandPoseObservationJointsGroupNameAll` ã§ã€ãƒ‘ãƒ¼ãƒ„å…¨éƒ¨ã‚’å‘¼ã³å‡ºã—ã¦ã„ã¾ã™ã€‚

[VNHumanHandPoseObservationJointsGroupNameAll | Apple Developer Documentation](https://developer.apple.com/documentation/vision/vnhumanhandposeobservationjointsgroupnameall)

##### `VNHumanHandPoseObservationJointsGroupNameAll` ãŒ`VNIPOAll` ã¨åˆ¤æ˜ã™ã‚‹ã¾ã§

Swift ã‚„ Objective-C ã§ã™ã¨ã€`.all` ã‚„`VNHumanHandPoseObservationJointsGroupNameAll` ã§å‘¼ã³å‡ºã™ã“ã¨ã«ãªã‚Šã¾ã™ãŒã€æ™‚ã€…`objc_util` ã§ã¯å‘¼ã³å‡ºã›ãªã„å ´é¢ã‚‚ã‚ã‚Šã¾ã™ã€‚

ç‰¹ã« Global Variable ã®ã‚ã‚‰ã‹ã˜ã‚å®šç¾©ã•ã‚Œã¦ã„ã‚‹å¤‰æ•°åã§ã™ã­ã€‚

ä»Šå›`VNIPOAll` ã‚’è¦‹ã¤ã‘å‡ºã—ãŸæ–¹æ³•ã¯:

```py
for result in request_list:
  print(result.availableJointsGroupNames())
```

ã¨ã€å…ˆã«ã‚°ãƒ«ãƒ¼ãƒ—åã®æƒ…å ±ã‚’ç¢ºèªã—ã¾ã—ãŸ:

```
(
    VNHLRKT,    <- è¦ªæŒ‡ï¼Ÿ Thumb
    VNHLRKM,    <- ä¸­æŒ‡ï¼Ÿ Middle
    VNHLRKI,    <- äººå·®ã—æŒ‡ï¼Ÿ Index
    VNHLRKR,    <- è–¬æŒ‡ï¼Ÿ Ring
    VNHLRKP,    <- å°æŒ‡ï¼Ÿ Little ï¼Ÿ
    VNIPOAll    <- ã“ã‚Œã£ã½ã„ï¼
)
```

[VNHumanHandPoseObservationJointsGroupName | Apple Developer Documentation](https://developer.apple.com/documentation/vision/vnhumanhandposeobservationjointsgroupname?language=objc)

https://developer.apple.com/documentation/vision/vnhumanhandposeobservationjointsgroupname?language=objc

[VNHumanHandPoseObservationJointName | Apple Developer Documentation](https://developer.apple.com/documentation/vision/vnhumanhandposeobservationjointname?changes=_3_1__1&language=objc)

https://developer.apple.com/documentation/vision/vnhumanhandposeobservationjointname?changes=_3_1__1&language=objc

`.all` ã ã¨æ€ã‚ã‚Œã‚‹`'VNIPOAll'` ã‚’å…¥ã‚Œã¦ã¿ã‚‹ã¨:

```py
_all = 'VNIPOAll'  # VNHumanHandPoseObservationJointsGroupNameAll

for result in request_list:
  handParts = result.recognizedPointsForJointsGroupName_error_(_all, None)
  print(handParts)
```

å‡ºåŠ›çµæœã¯ã€21 ãƒ¶ã®åå‰ã¨æ•°å€¤ã§ã—ãŸ:

```
{
    VNHLKIDIP = "[0.485334; 0.583736]";
    VNHLKIMCP = "[0.166403; 0.488322]";
    VNHLKIPIP = "[0.342590; 0.580520]";
    VNHLKITIP = "[0.569792; 0.570696]";
    VNHLKMDIP = "[0.403824; 0.585380]";
    VNHLKMMCP = "[0.139485; 0.497076]";
    VNHLKMPIP = "[0.296893; 0.583691]";
    VNHLKMTIP = "[0.477001; 0.572641]";
    VNHLKPDIP = "[0.377817; 0.574937]";
    VNHLKPMCP = "[0.244330; 0.498787]";
    VNHLKPPIP = "[0.299134; 0.569371]";
    VNHLKPTIP = "[0.428175; 0.559813]";
    VNHLKRDIP = "[0.373153; 0.578908]";
    VNHLKRMCP = "[0.167453; 0.499612]";
    VNHLKRPIP = "[0.283478; 0.573761]";
    VNHLKRTIP = "[0.436168; 0.565271]";
    VNHLKTCMC = "[0.512299; 0.336474]";
    VNHLKTIP = "[0.606151; 0.494821]";
    VNHLKTMP = "[0.598214; 0.402705]";
    VNHLKTTIP = "[0.589989; 0.569710]";
    VNHLKWRI = "[0.241853; 0.266611]";
}
```

[VNRecognizedPoint | Apple Developer Documentation](https://developer.apple.com/documentation/vision/vnrecognizedpoint?language=objc)

https://developer.apple.com/documentation/vision/vnrecognizedpoint?language=objc

Documentation ã‚’ã¿ã¦ã‚‚ã€5 æœ¬ã®æŒ‡ã«ãã‚Œãã‚Œ 4 ã¤ã®ãƒã‚¤ãƒ³ãƒˆã¨ã€æ‰‹é¦–ã§è¨ˆ 21 ã‚ã‚‹ã®ã§ã€ç„¡äº‹ã«å–ã‚Œã¦ãã†ã§ã™ã€‚

ã‚¢ãƒ«ãƒ•ã‚¡ãƒ™ãƒƒãƒˆã®ç•¥å­—ãŒéãã‚‹ã“ã§ã€Documentation ã‚„ã“ã®ã‚ˆã†ãªã‚‚ã®ã¨è¦‹æ¯”ã¹ãªãŒã‚‰è¦‹å½“ã‚’ã¤ã‘ã¦ã„ãã¾ã™ã€‚

[Body Anatomy: Upper Extremity Joints | The Hand Society](https://www.assh.org/handcare/safety/joints)

https://www.assh.org/handcare/safety/joints

è¦å‰‡æ€§ã¨ã—ã¦ã€`VNHLK` ã¾ã§ã¯åŒæ§˜ã§ã™ã€‚ã„ã‚ã„ã‚ã¨æƒ…å ±ã‚’ã‹ãé›†ã‚ãŸä¸Šã§ã®å‹˜ã§ã™ãŒ:

- `VN`
  - Vision
- `H`
  - Hand
- `L`
  - Landmark
- `K`
  - Key

ãã‚Œãã‚Œã®æŒ‡ã‚’ä¸€æ–‡å­—ã§è¡¨ã—:

- `I`: index äººå·®ã—æŒ‡
  - `DIP`
    - ç¬¬ä¸€é–¢ç¯€
  - `MCP`
    - ä»˜ã‘æ ¹
  - `PIP`
    - ç¬¬äºŒé–¢ç¯€
  - `TIP`
    - å…ˆ
- `WRI`
  - æ‰‹é¦–

äººå·®ã—æŒ‡ã®ã€æŒ‡å…ˆã‚’æŒ‡å®šã—ã¦ã¿ã¾ã™:

```py
recognizedPoint = handParts[_point]

x_point = recognizedPoint.x()
y_point = recognizedPoint.y()
self.cameraView.showPoints(x_point, y_point)
```

### æƒ…å ±ã®å¯è¦–åŒ–

ãŸãã•ã‚“å–ã‚Œãã†ãªã®ã§`ui.TextView` ã«ã¦ã€`'VNIPOAll'` ã®æƒ…å ±ã‚’ä¸€æ‹¬ã§æµã—è¾¼ã¿ã€ãƒ†ã‚­ã‚¹ãƒˆè¡¨ç¤ºã«ã€‚

äººå·®ã—æŒ‡ã®æŒ‡å…ˆã‚’ã€Tracking ã¨ã—ã¦ã¿ã¾ã—ã‚‡ã†ã€‚

#### `ui.TextView` ã®å‡¦ç†

æ–‡å­—åˆ—ã‚’æŠ•ã’è¾¼ã‚ã°ã„ã„ã®ã§ã€`update_log_area` ãƒ¡ã‚½ãƒƒãƒ‰ã‚’é–“å£ã«ã—ã¦ã€`delegate` ã§å‡¦ç†ã•ã‚ŒãŸã‚‰å‹æ‰‹ã«æ›´æ–°ã•ã‚Œã¾ã™ã€‚

```py
class CameraView(ui.View):
  def __init__(self, *args, **kwargs):
    self.log_area = ui.TextView()
    self.log_area.editable = False
    self.log_area.flex = 'WH'
    self.log_area.font = ('Inconsolata', 10)
    self.log_area.bg_color = (0.0, 0.0, 0.0, 0.0)

    # layer ã‚’é‡ã­ãŸå¾Œã§ãªã„ã¨ã€éš ã‚Œã¦ã—ã¾ã†
    self.add_subview(self.log_area)

  def update_log_area(self, text):
    self.log_area.text = f'{text}'
```

æ–‡å­—åˆ—é‡ã®ç¸¦å¹…ã‚µã‚¤ã‚ºèª¿æ•´ãŒé¢å€’ã ã£ãŸã®ã§ã€å…¨ç”»é¢å‰æã§è¨­å®šã‚’ã—ã¦ã„ã¾ã™ã€‚èƒŒæ™¯è‰²ã‚’é€éã•ã›ã¦ã‚«ãƒ¡ãƒ©ã® View æƒ…å ±ã‚’ã¾ã‚Œã‚‹ã‚ˆã†ã«ã—ã¦ã„ã¾ã™ã€‚

`log` ã®æ–¹ã®ç¢ºèªãŒå„ªå…ˆã§ã‚ã‚Œã°ã€èƒŒæ™¯é€éåº¦åˆã„ã‚’ä¸Šã’ã¦ã„ã‘ã°ãƒ†ã‚­ã‚¹ãƒˆãŒè¦‹ã‚„ã™ããªã‚‹ã¨æ€ã„ã¾ã™ã€‚

ã¾ãŸã€`self.add_subview(self.log_area)` ã®å‘¼ã¶ä½ç½®ã‚‚è€ƒãˆã¦ãŠã‹ãªã„ã¨ã€ã‚«ãƒ¡ãƒ©ã® View Layer ã®æ–¹ãŒä¸Šã«è¢«ã•ã‚‹çŠ¶æ…‹ã«ãªã£ã¦ã„ã¾ã†ã®ã§ã€é †ç•ªã‚’æ°—ã‚’ã¤ã‘ã¾ã™ã€‚

#### `overlayLayer` ã§ã®æç”»

æç”»ã¨ã—ã¦ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã®ç¢ºèªãŒã§ãã‚Œã° OK ã®æ€æƒ³ã§ã€é›‘ã«è¨­å®šã—ã¦ã—ã¦ã—ã¾ã£ã¦ã„ã¾ã™ã€‚

ã¾ã `CAShapeLayer`, `UIBezierPath` ãŒä½¿ã„æ…£ã‚Œã¦ã„ãªã„æ„ŸãŒã‚ã‚Šã¾ã™ã€‚ã€‚ã€‚

æ•°å€¤æŠ•ã’ãŸã‚‰ã€ãã®ä½ç½®ã«æç”»ã•ã‚Œã‚‹ã‚ˆã†ã«ã—ã¦ã„ã¾ã™ã€‚

```py
@on_main_thread
def showPoints(self, _x, _y):
  _, _, _width, _height = parseCGRect(self.overlayLayer.frame())
  x = _width - (_width * (1 - _x))
  y = _height - (_height * _y)

  radius = 8.0
  startAngle = 0.0
  endAngle = pi * 2.0

  arc = UIBezierPath.new()
  arc.addArcWithCenter_radius_startAngle_endAngle_clockwise_(
    (x, y), radius, startAngle, endAngle, True)

  self.overlayLayer.setPath_(arc.CGPath())

```

ã‚­ãƒ¢ã¯ã€ãƒ‡ã‚³ãƒ¬ãƒ¼ã‚¿`@on_main_thread` ã§ã™ã­ã€‚

`ui.View` ã®å‡¦ç†ã¨ã¯åˆ¥ã®å‡¦ç†ã¨ãªã‚‹ã®ã§ã€ãƒ‡ã‚³ãƒ¬ãƒ¼ã‚¿ã‚’ã¤ã‘ãªã„ã¨æç”»ã•ã‚Œã¾ã›ã‚“ã€‚

ã¾ãŸã€`self.log_area` ã§ã‚ã‚‹`ui.TextView` ã¯ã€`ui.View` thread ã§èµ°ã£ã¦ã„ã‚‹ãŸã‚ã‹ã€ãƒ‡ã‚³ãƒ¬ãƒ¼ã‚¿ã‚’ã¤ã‘ãšã¨ã‚‚æ•°å€¤æ›´æ–°ãŒã•ã‚Œã¦ã„ã¾ã™ã€‚

## æ¬¡å›ã¯

ã“ã‚“ãªã«ã‚‚ã‚¹ãƒ«ã‚¹ãƒ«ã¨ã€æŒ‡ã® Tracking ã‚’ã—ã¦ãã‚Œã‚‹ãªã‚“ã¦é©šãã§ã™ã­ã€‚

`UIBezierPath` ã‚’ã†ã¾ãä½¿ã„ã¤ã¤ã™ã‚‹ã¨ã€é¢ç™½ã„è¡¨ç¾ãŒã§ããã†ã§ã™ã€‚

ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã®æ¤œå‡ºãŒã§ããŸã®ã§ã€å‹•ç”»ãƒ•ã‚¡ã‚¤ãƒ«ã§ã®æ¤œå‡ºã‚‚ã•ã»ã©é›£ã—ãã¯ãªã„ã§ã—ã‚‡ã†ã€‚

ç§ãŒ Vision Framework ã‚’ä½¿ã„å§‹ã‚ã¦ã‹ã‚‰æ—¥ãŒæµ…ãã€å†…å®¹ã¨ã—ã¦ã¾ã¨ã¾ã‚Šãã‚Œã¦ã„ãªã„éƒ¨åˆ†ã‚‚å¤šãã‚ã‚Šã¾ã—ãŸã€‚

ãŒã€å„æŒ‡ã®ãƒã‚¤ãƒ³ãƒˆåã‚’èª¿æŸ»ã—åˆ¤æ˜ã—ãŸã¨ã

ã€ŒVision Framework ã®èª¿ã¹ç‰©ã§ã“ã‚“ãªä¸æ¯›ãªã“ã¨ã‚ã‚‹ï¼Ÿã€

ã¨æ€ã£ã¦ã—ã¾ã„ã‚·ã‚§ã‚¢ã›ã–ã‚‹ã‚’å¾—ã¾ã›ã‚“ã§ã—ãŸã€‚

Pythonista3 ã®ã¿ã§ç”Ÿãã‚‹ç„¡é§„çŸ¥è­˜ã€‚ã€‚ã€‚

ä»Šå›ã§ Vision Framework ã¯çµ‚äº†ã—ã€æ¬¡å›ã‚ˆã‚Š[Pythonista3 Advent Calendar 2022](https://qiita.com/advent-calendar/2022/pythonista3) ã®æœ€çµ‚ç« ã¸å‘ã‹ã„ãŸã„ã¨æ€ã„ã¾ã™ã€‚

WebView ã‚’ã‚„ã‚Šã¾ã™ã€‚ã‚ˆã‚ã—ããŠé¡˜ã„ã—ã¾ã™ã€‚

ã“ã“ã¾ã§ã€èª­ã‚“ã§ã„ãŸã ãã‚ã‚ŠãŒã¨ã†ã”ã–ã„ã¾ã—ãŸã€‚

ğŸ‘‡ : 24 æ—¥ç›®

https://qiita.com/pome-ta/items/52053dd6c9e39da6a29a

## ã›ã‚“ã§ã‚“

### Discord

Pythonista3 ã®æ—¥æœ¬èªã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£ãƒ¼ãŒã‚ã‚Šã¾ã™ã€‚ã¿ãªã•ã‚“å„ªã—ãã¦ã€ã‚ã‹ã‚‰ãªã„ã¨ã“ã‚ã‚‚è¦ªèº«ã«æ•™ãˆã¦ãã‚Œã‚‹ã®ã§ã“ã®æ©Ÿä¼šã«è¦—ã„ã¦ã¿ã¦ãã ã•ã„ã€‚

https://t.co/0IOW2hn1VC

### æ›¸ç±

iPhone/iPad ã§ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°ã™ã‚‹æœ€å¼·ã®æœ¬ã€‚

- [Python ã‚„ Jupyter ã§ iPhone/iPad å…ˆç«¯æ©Ÿèƒ½ã‚’ç°¡å˜ï½¥è‡ªç”±ã«ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°ï¼ã€Œæ´»ç”¨ç¯‡ã€ï¼šhirax](https://techbookfest.org/product/1WiyV4LEev3f4YrzesRKWV?productVariantID=axX32srsSgtLtZWUtjkj99)

https://techbookfest.org/product/1WiyV4LEev3f4YrzesRKWV?productVariantID=axX32srsSgtLtZWUtjkj99

- [Python ã‚„ Jupyter ã§ iPhone/iPad å…ˆç«¯æ©Ÿèƒ½ã‚’ç°¡å˜ï½¥è‡ªç”±ã«ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°ï¼ã€ŒåœŸå°ç¯‡ã€ï¼šhirax](https://techbookfest.org/product/wTZTyeibm5GQ5XgdfMrEBV?productVariantID=kRDmN1udbEYZUWbETdwL8r)

https://techbookfest.org/product/wTZTyeibm5GQ5XgdfMrEBV?productVariantID=kRDmN1udbEYZUWbETdwL8r

### ãã®ä»–

- ã‚µãƒ³ãƒ—ãƒ«ã‚³ãƒ¼ãƒ‰

[Pythonista3 Advent Calendar 2022](https://qiita.com/advent-calendar/2022/pythonista3) ã§ã®ã‚³ãƒ¼ãƒ‰ã‚’ã¾ã¨ã‚ã¦ã„ã‚‹ãƒªãƒã‚¸ãƒˆãƒªãŒã‚ã‚Šã¾ã™ã€‚

ã‚³ãƒ¼ãƒ‰ã®ã‚¨ãƒ©ãƒ¼ã‚„å¤‰ãªã¨ã“ã‚ã‚„æ”¹å–„ç‚¹ãªã©ã€‚ã”æŒ‡æ‘˜ã‚„ PR ãŠå¾…ã¡ã—ã¦ãŠã‚Šã¾ã™ãƒ¼

https://github.com/pome-ta/Pythonista3AdventCalendar2022sampleCode

- Twitter

ãªã‚“ã—ã‹ã‚¬ãƒãƒ£ã‚¬ãƒãƒ£ã—ã¦ã„ã¾ã™ãŒã€ãŠæ°—å…¼ã­ãªããŠå£°ãŒã‘ãã ã•ã„ã¾ã›ãƒ¼

https://twitter.com/pome_ta93

<blockquote class="twitter-tweet"><p lang="ja" dir="ltr">ã‚„ã‚Œã‚‹ã‹ã€ã‚„ã‚Œãªã„ã‹ã€‚ã§ã¯ãªãã€ã‚„ã‚‹ã‚“ã ã‘ã©ã‚‚ã€ç´¹ä»‹èª¬æ˜ã™ã‚‹ã“ã¨ã¯å°½ããªã„ã¨æ€ã†ã‘ã©ã€ç· ã‚åˆ‡ã‚Šå®ˆã‚Œã‚‹ã‹ï¼Ÿã£ã¦è©±ã‚ˆï¼ï¼ˆã‚¯ã‚ºï¼‰<br><br>Pythonista3 Advent Calendar 2022 <a href="https://t.co/JKUxA525Pt">https://t.co/JKUxA525Pt</a> <a href="https://twitter.com/hashtag/Qiita?src=hash&amp;ref_src=twsrc%5Etfw">#Qiita</a></p>&mdash; pome-ta (@pome_ta93) <a href="https://twitter.com/pome_ta93/status/1588570697777152006?ref_src=twsrc%5Etfw">November 4, 2022</a></blockquote> <script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>

- GitHub

åŸºæœ¬çš„ã« GitHub ã«ã‚³ãƒ¼ãƒ‰ã‚’ã‚ã’ã¦ã„ã‚‹ã®ã§ã€ä½•ã«ãƒãƒã£ã¦ä½•ã‚’å®Ÿè£…ã—ã¦ã„ã‚‹ã®ã‹è¦³æ¸¬ã§ãã‚‹ã¨æ€ã„ã¾ã™ã€‚

https://github.com/pome-ta
